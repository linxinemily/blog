[{"categories":null,"contents":" 前提 Facebook ios sdk 在 17.0.0 版本後，要求必須實作 Limited Login，並使用 JWT token 進行驗證，否則在某些情況下會有非預期錯誤(ref)。\n流程為：\nclient 端（ios App） 會將以下資訊：\n登入嘗試要求的權限 追蹤偏好設定 nonce（隨機生產的亂數，每次請求都須不同，用來做後續的驗證） 帶入請求，向 FB 取得用戶資料與一組 JWT token。（實作範例可參考官方文件）\n接著 client 會將 token 傳給我們的後端 server，後端需要驗證 token 是否合法。\n重點就在於後端驗證 token 這段，官方文件非常簡明概要，並沒有附上實作範例。所以特此紀錄一下踩坑過程。\n如何驗證 JWT Token 首先，文件要我們確認以下三件事：\n1. That the JWT is well formed token 須為合法的 JWT token。也就是包含一組用 Base64Url-encoded 的 header, payload, signature，每個部分解碼後都必須為合法的 json 格式。\n2. The signature 解碼後的 signature 部分需要和以下步驟產生的結果相同：\n藉由呼叫 JWKS endpoint 取得一組 public key\n打 JWKS endpoint 會得到一個 json 物件，回傳多組 pub key：\n1 2 3 4 5 6 7 8 9 10 \u0026#34;keys\u0026#34;: [ { \u0026#34;kid\u0026#34;: \u0026#34;d458ab5237807dc6718901e522cebcd8e8157791\u0026#34;, \u0026#34;kty\u0026#34;: \u0026#34;RSA\u0026#34;, \u0026#34;alg\u0026#34;: \u0026#34;RS256\u0026#34;, \u0026#34;use\u0026#34;: \u0026#34;sig\u0026#34;, \u0026#34;n\u0026#34;: \u0026#34;uPyWMhNfNsO9EtiraYI0tr78vnkiJmzsmAAUd8hLHF5vPXDn683aQKZQ2Ny5lObigNmbHI5tt5y0o5m0RuZjJTj081uWm7Z901boO-p4VLwEONzjh4vTp2ZQ7aMjo17kMBzInHqz9iruWeB94dEu_LKYdQnDI6rweD_-chWWTR4mc7xbeaNozLHYzjEisSrIM3xIry2lZv5Mh334ZoahcTXGouFtU2XV_HvStXthwhoAtizQK7s2yJlBz8qlQK2lFNojRzd95f2bkynRnIvcpoF-qHZbOBTCIf-6TLp23qShs-XvbCkwHMhzvCPxcuZx3GNfCQkyTxeM5IGIMlWZ8w\u0026#34;, \u0026#34;e\u0026#34;: \u0026#34;AQAB\u0026#34; }, ... 而要使用哪一組 key，需要用解碼的 header 當中所帶的一個屬性 kid 去比對，找出相同 kid 的那把 key。\n使用解碼後的 header 當中指定的演算法(欄位： alg)以及上述的 public key 對 Base64Url-encoded 的 header 跟 payload 連接的值(Base64url-encoded header + \u0026quot;.\u0026quot; + Base64url-encoded payload) 加密處理後的結果進行 Base64url-encode。\n3. The standard claims 檢查解碼後的 payload 幾個屬性值是否符合預期：\n檢查 token 有無過期（欄位： exp）\nToken issuer 是否正確（欄位： iss ）\n文件上沒有說明 issuer 的值為何（照理來說會是 Facebook 的某個網域或端點），後來是在某篇討論串當中找到，在限制登入的 OIDC 權杖的 OIDC 端點 \u0026gt; 探索端點 裡面：\n1 2 3 4 { \u0026#34;issuer\u0026#34;: \u0026#34;https://www.facebook.com\u0026#34;, //... } Audience 是否與 FB App ID 相同 （欄位： aud ）\nApp ID 可以到 Facebook developer 後台查看\nNonce 是否正確（欄位： nonce ）\n就是上面前端傳給 FB 產 token 時帶的亂數，前端在發 request 給後端時需一併攜帶過來。（後端才能驗證 payload 當中的 nonce 是否與之相同）\n實作 以上解析 JWT token 與驗證 signature 的部分都有現成的 JWT 套件可以替我們完成，在這邊使用 golang 搭配以下兩個套件來實作：\ngolang-jwt/jwt/v5：解析 JWT token 與驗證 signature lestrrat-go/jwx/jwk：解析 JWKS public key 首先定義 structs 接收需要的資料：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 type ( Auth struct { JWTToken string Nonce string APIHost string AppID string JWKSEndpoint string Client *http.Client } // 檢查 token 有無過期、驗證 issuer 與 audience 都是屬於 JWT 規範中定義的一些常見聲明 // 可以使用 jwt.RegisteredClaims 即可 // 但因為我們有攜帶 `Nonce`，為 FB 自定義的部分，所以需要自訂 Claim ClientClaims struct { jwt.RegisteredClaims Nonce string `json:\u0026#34;nonce\u0026#34;` } ) func NewFBAuth(jwtToken, nonce string) *Auth { return \u0026amp;Auth{ JWTToken: jwtToken, Nonce: nonce, //屬於敏感資訊，以 env config 形式取得 APIHost: config.Config.FacebookAuth.APIHost, // 預期的 issuer 值 AppID: config.Config.FacebookAuth.AppID, // 預期的 audience 值 JWKSEndpoint: config.Config.FacebookAuth.JWKSEndpoint, Client: \u0026amp;http.Client{Timeout: 30 * time.Second}, } } 接著實作驗證方法的部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 func (a *Auth) ValidateJWTToken() error { set, err := a.fetchPublicKeySet() // 取得 JWKS Public key if err != nil { return err } token, err := jwt.NewParser( // 使用套件內建的 validator 驗證標準聲明的欄位 jwt.WithExpirationRequired(), // 檢查 token 有無過期 jwt.WithIssuer(a.APIHost), // Token issuer 是否正確（等於 a.APIHost） jwt.WithAudience(a.AppID), // Audience 是否正確（等於 a.AppID） ).ParseWithClaims(a.JWTToken, \u0026amp;ClientClaims{}, func(token *jwt.Token) (interface{}, error) { // 取得 header 的 kid 值，用來尋找 JWKS 端點回傳 json 當中匹配的 pub key keyID, ok := token.Header[\u0026#34;kid\u0026#34;].(string) if !ok { return nil, errors.Str(\u0026#34;expecting JWT header to have string kid\u0026#34;) } keys := set.LookupKeyID(keyID) if len(keys) == 0 { return nil, errors.Str(\u0026#34;can not find kid\u0026#34;) } var key interface{} if err := keys[0].Raw(\u0026amp;key); err != nil { return nil, err } return key, nil }) if err != nil { return err } else if claims, ok := token.Claims.(*ClientClaims); ok { // 由於 Nonce 為自定義的聲明屬性，需要額外手動驗證 if claims.Nonce != a.Nonce { return errors.Errorf(\u0026#34;nonce mismatch: %s != %s\u0026#34;, claims.Nonce, a.Nonce) } } else { return errors.Errorf(\u0026#34;expecting *ClientClaims, got %T\u0026#34;, token.Claims) } return nil } func (a *Auth) fetchPublicKeySet() (*jwk.Set, error) { resp, err := a.Client.Get(a.JWKSEndpoint) if err != nil { return nil, err } respBody, err := io.ReadAll(resp.Body) if err != nil { return nil, err } defer resp.Body.Close() return jwk.ParseBytes(respBody) } 驗證成功即可向前端回傳使用者登入成功。\n碎碎念 猜測是因為後端語言太多，各語言也都有自己的 jwt 套件，所以官方才沒有放驗證 Token 的實作範例，但像上面提到的 kid、issuer 應該可以說明更清楚一點。不過也算是藉機學習了，感謝 Facebook。（？）\n","date":"May 19","permalink":"//localhost:1313/posts/validate-facebook-limited-login-jwt-token/","tags":["Golang","Third-Party Integration"],"title":"Validate Facebook Limited Login JWT Token in Golang"},{"categories":null,"contents":" 前言 從去年八月左右開始參加一堂水球軟體學院所開設的「精通軟體設計模式之旅」線上課程，至今也算是完成了一個里程碑，想說是時候可以來分享一下從參加旅程至今的點點滴滴，從參加動機、課程體驗到學習心得，算是為自己這段學習做一個回顧性的紀錄。\n參加動機與課程體驗 大概在一年多前從網路社群上面得知有這樣一個課程準備展開，但那時候還只有推出「免費試吃」課程，填寫表單就可以排隊抽籤，抽中的才有參加試吃課程的資格。結果一直沒被抽中，後來終於等到了第一梯次正式收費的課程開跑就直接報名了。所以當初到底是什麼吸引了我，讓我這麼想報名這個課程呢？\n衝著老師和挑戰題而來 其實在接觸課程之前，就曾經在課程老師水球潘的 YouTube 頻道看過他講解的設計模式之路系列影片， 當時第一次覺得居然有人有辦法把設計模式的概念講解得這麼有趣，讓人會想要像看劇一樣繼續追下去。不過因為該系列影片似乎因為水球本人的課業因素所以後來停更了，覺得可惜之外，也只能期待哪天他會突然開始更新。結果後來在社群看到他本人發文推出新課程時，真的是就像是追許久的 YT 沈寂一陣子後突然復出一樣的驚喜！\n此外，課程中除了教學影片，還包含許多實戰題作業。對我來說，這一點真的是一個很大的吸引力。在自已過去的軟體開發經歷中，很多時候幾乎是透過動手實作才真正理解一個概念，所以我認為實作在學習軟體開發相關技能時是很重要的一環。 同時，由於以往對設計模式的理解可以說僅止於知道幾個名詞，雖然曾看過相關書籍，但因為平常也沒有什麼應用場景或實作的機會，覺得是時候該把這塊補起來。\n旅程中不錯的服務 另外還有一些旅程所提供的服務，是我在旅程當中逐漸體會到也很重要的部分：\n協助檢驗學習成果 輸出的結果，往往也需要經過檢驗，才能確保有吸收到正確的知識。課程當中會安排每週固定時間的「TA Hour」來針對作業進行 Code Review，除了檢討作業之外，若過程中有遇到什麼問題或困難，都能夠在 TA Hour 中提出，並得到立即的反饋。\n活躍的學習社群 以往參加過某些線上課程，有的也是會主打塑造學習社群，但可能剛好我參加過的課程在這部分都跟想像中有差距，學員之間實際上並不會有太多互動，因此一開始對於這部分沒有抱太大期待。初期也真的幾乎是單打獨鬥，頂多有時候有問題在群組發問，有滿多熱心大大會回應，但此時的互動性也不高（對於一個害羞內向的人（會被打ㄇ，應該不會吧這是我的部落格欸）來說，不算是個能很自在的發言的場所）。但後來推出了所謂的「公會系統」，讓學員（在旅程中都稱為冒險者）能夠自由組成學習小組，能夠彼此討論作業或分享進度等等，於是我就順勢加入了其中一個公會，認識了好幾個厲害的夥伴，這才真的體會到互相交流成長的感覺，有人一起寫作業真的會比較有動力！\n以上這兩點我後來想想真的算是滿重要讓我可以持續課程的部分，因為以前兩點（1.老師教學品質高 2.豐富的實作練習）來說，我就曾經上過 Berkeley 一個很有名的線上公開課程 CS 61B，內容是真的非常優質，也有配合大量的練習題，但我最後還是沒能完課（大概上到一半而已🥲）。\n當初沒有繼續的主因當然是我就懶嘛，但到了軟體設計模式精通之旅，多了有人協助 Code Review 檢驗學習成果＋有同儕能互相交流討論，居然可以讓我這種會半途放棄的人繼續上課寫作業，可見這兩點真的是非常有幫助的！\n學習心得 重新認識物件導向，從 OOA 開始 這門課雖然稱之為「設計模式精通之旅」，但並沒有像一般大部分書籍或教學劈頭就把 GoF 的 23 個設計模式全部丟給我們，反倒是從重新認識物件導向開始，以及重新釐清「物件」和「類別」的概念，還有「類別」之間的關係。而這一切，都是為了要先打好基本功，也就是在做設計之前的第一步，先建立出「領域模型」，將 UML 類別圖畫出來，捕捉各個物件/類別的屬性和行為，並且標示他們之間的關聯，而這階段也稱之為 OOA(Object-Oriented Analysis)/物件導向分析。\n⬆︎進行 OOA 繪製 UML 類別圖，將各個物件/類別的屬性和行為定義出來，並且標示他們之間的關聯\nOOA 是整門課當中最基礎也最重要的一步，因為當有了 OOA 我們才能進行接下來的設計，也就是 OOD(Object-Oriented Design)/物件導向設計，而這時才是設計模式「可能」會出場的時候。為什麼這邊會說「可能」？因為設計模式並不是生來就讓你想套就套的，當然這樣也不是不行，只是通常這種毫無理由套用設計模式的行為，通常會被認為是「過度設計/Over Design」的，也是課程中很常呼籲大家不要一不小心成為了軟體酒駕過度設計師。\nOOD 設計要點：覺察 Forces，得出 Problem，找到 Pattern(Solution) 先回到一開始的定義，所謂的模式，就是一套可以解決特定情境底下的問題的方法，且這套方法經過前人反覆驗證並被傳承下來，白話文就是解決特定問題的一套 SOP。每個設計模式背後都是為了解決某個 特定情境(Context)底下的問題(Problem) 而生，所以說假使問題不存在，那麼也就沒有套用設計的必要。如果再將這些所謂的問題一一攤開來看，會發現其實正是因為一道道 Forces 彼此相互衝突，進而讓問題呼之欲出，此時才會需要透過特定模式(Pattern)的 Form 來解決問題——找到解決方案(Solution)，最後得到套用模式之後的結果(Resulting Context)成功化解衝突的 Forces。\n這裡所指的 Forces，舉例來說像是「未來可能會繼續擴充新的行為」、「對程式碼維護性的要求」、「須滿足特定的商業邏輯」，每一項都是一道 Force，而多道 Forces 若同時存在又彼此互相衝突，就會令工程師感受到滿滿的壓抑感。\n⬆︎OOD：以為 OOA 基礎，察覺彼此衝突的 Forces 之後定義出 Problem，並找到 Problem 對應的 Solution，套用 Pattern 後的 Resultinng Context\n『如果沒有察覺到 Forces，就說明沒有設計難題 Problem，也就不必要討論 Solution，更沒必要思考 Pattern。』\n唯有精準的察覺到每一道彼此衝突的 Forces 後，才能看出問題所在，再從腦袋中索引該問題適合的解決方案，最後一步才是套用設計模式。我認為真正困難的點都是在察覺 Forces，尤其在做魔王題時，偶爾會有感受不到 Forces 的狀況，這種時候通常都是由於沒有把需求看仔細，也就是在做 OOA 時，可能漏捕捉了某些重要的元素或行為。但連作業都會有這種情況發生了，更何況是現實的商業開發環境，作業因為是刻意要訓練我們，一定會暗藏 Forces，且需求說明這麽完整，我硬找出來即可；但現實當中，我怎麼可能知道哪些是暗藏的？常常連需求都不清不楚了。不過這也代表察覺 Forces 的能力還需要更進一步的提升，在未來面對實際需求時，才更有可能派得上用場。\nOOP 就是按照 OOAD 藍圖施工 最後，終於得到了完成 OOD 的 UML 類別圖版本，這時候才真的要開始動手寫程式，進入 OOP(Object-oriented programming)/物件導向程式開發的階段。這時候基本上不管使用什麼語言，都可以照著 OOD 這張藍圖，快速地去完成程式實作的部分。\n按照這個 SOP (OOA → OOD → OOP) 進行幾次作業之後，明顯感受到大多數思考程式架構的部分都是在 OOA 與 OOD 階段，而進入 OOP 後，通常都是開始進入碼農模式（除了一些比較複雜的題目，要實現特定演算法或是處理非同步機制需要比較多思考），就像工人依照建築藍圖去施工一樣。\n掌握軟體設計精髓，避免過度設計 我想 OOAD 的部分，正是軟體設計的精髓所在，這也是我在過往開發經歷中幾乎沒有培養過的能力，畢竟自己平常工作上大多是 CRUD，手邊大概 80% 以上的工作都是運用框架或工具即可處理的業務需求，如果當初要叫我寫一個 Domain Logic 非常豐富的卡牌遊戲，我可能根本寫不出來。而旅程當中已經寫過了比大小、大老二和 RPG 遊戲，未來還會繼續挑戰到 IoC 容器框架、Web Framework 等等難度更進階的題目，雖然不確定自己能否走到最後一關（但願），不過從現回頭看，自己的軟體設計技能已經成長了不少。\n一開始的我純粹只是想學習如何使用設計模式，卻完全忽略了「爲什麼要學習/使用設計模式」，直接在旅程的一開始就被點出了自己從未思考過，卻非常核心的問題。要是沒有參加旅程，我可能就會繼續用以往的思維，只是因為熟悉某些設計模式或單純為了炫技而套模式。而就以一個平常大多數使用框架和工具就能完成日常 80% 工作的人來說，設計模式確實很少機會派得上用上（大多數會使用模式的部分，框架或工具都幫我們做掉了），但我認為這趟旅程所帶來最大的收穫就是對於 OOAD 的掌握能力，同時培養了軟體架構思維，懂得如何避免過度設計，光這一點就讓我覺得非常值得了。\n","date":"Aug 16","permalink":"//localhost:1313/posts/design-pattern-by-waterballsa-learning-experience/","tags":["Software Development"],"title":"培養軟體架構思維，拒絕過度設計——軟體設計模式精通之旅心得"},{"categories":null,"contents":" 題目概述 給定兩個單向 Linked List 的第一個節點 (head)，兩個 List 可能會在某個節點會合成為一個 List，要求找出會合節點並回傳。若兩個 List 並無會合，則回傳 null。\n其中，會合節點必須是指向同一個實例（指標），也就是即使兩個節點的值相同，但為不同實例，不能算是會合節點。\n題目連結\n解法一：HashMap 也是第一時間想到的方法，先遍歷其中一個 List，使用一個 Hashmap 紀錄 key 為實例指標，值為節點的值（其實值為何並不重要），接著再遍歷第二個 List，判斷當前節點是否存在於 map 當中，有的話則立即返回，都遍歷完的話代表兩個 List 並無相同元素，也就是不存在會合節點。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func getIntersectionNode(headA, headB *ListNode) *ListNode { m1 := make(map[*ListNode]int) curA := headA for curA != nil { m1[curA] = curA.Val curA = curA.Next } curB := headB for curB != nil { if _, ok := m1[curB]; ok { return curB } curB = curB.Next } return nil } 但這個方法其實會需要 O(n) 的空間複雜度，雖然可以被 Accepted，但並非最佳解。\n無法滿足 follow up 要求：空間複雜度 O(1)，時間複雜度 O(m+n)\n解法二：雙指針 送出後滑了一下 Solutions 當中其他強者的解法，才看到這個聰明的方法。\n配置兩個指針，都各自從 List A 和 List B 的 head 開始，指針1 將 List A 走到底後接著走 List B，同時，指針2 將 List B 走到底後接著走 List A。短的 List 會被先走完就會換到長的 List 去，而長的 List 走完也會換到短 List 去走，最終兩個指針就會走到交會的節點上。\n做了個簡單的動畫，直接看比較清楚：\n不管是先走完 A 再走 B，還是先走完 B 再走 A，當走到互換 List 那邊去之後，會在面臨交會點之前同步：\na1 → a2 → c1 → c2 → c3 → null(a走完換b) → b1 → b2 → b3 → c1\nb1 → b2 → b3 → c1 → c2 → c3 → null(b走完換a) → a1 → a2 → c1\nb3 的 next 為 c1 ， a2 的 next 也為 c1 ，得出交會點為 c1 。\n那如果當沒有交會點的時候會發生什麼事？用同樣的思考方式來看：\na1 → a2 → a3 → a4 → null(a走完換b) → b1 → b2 → b3 → null\nb1 → b2 → b3 → null(b走完換a) → a1 → a2 → a3 → a4 → null\n由於 b3 和 a4 的 next 都是 null，得出交會點為 null。\n如果List A 和 List B 的長度相同，則此解決方案將在不超過1次遍歷的情況下終止；如果兩個 List 的長度不同，則此解決方案將在不超過2次遍歷的情況下終止 \u0026ndash; 在第二次遍歷中，交換 A 和 B 會使 A 和 B 在第二次遍歷結束前同步。在第二次遍歷中，它們都具有相同的剩餘步驟，以確保它們同時（從技術上來說，是在同一次迭代中）到達第一個交會節點，或者同時到達 null。 by Java solution without knowing the difference in len!\n最後的 code：\n1 2 3 4 5 6 7 8 class Solution: def getIntersectionNode(self, headA: ListNode, headB: ListNode) -\u0026gt; Optional[ListNode]: p1 = headA p2 = headB while(p1 != p2): p1 = headB if p1 is None else p1.next p2 = headA if p2 is None else p2.next return p1 Reference Java solution without knowing the difference in len!： 這篇 Solution 底下有一個 BryanBoCao 大大的（應該是第一個）留言，當中有詳細的圖解說明，非常有助於理解。 ","date":"Jul 31","permalink":"//localhost:1313/posts/leetcode-160-intersection-of-two-linked-lists/","tags":["Algorithm"],"title":"[leetcode 筆記] 160. Intersection of Two Linked Lists"},{"categories":null,"contents":"接續上一篇文章：GraphQL Dataloader 在 Golang 當中的打開方法與原理解析（上）。\n在進入原始碼之前，先複習一下 use case。首先從 resolver 開始看起：\n1 2 3 4 5 // IconURL is the resolver for the icon_url field. func (r *roomFeatureResolver) IconURL(ctx context.Context, obj *model.RoomFeature) (*string, error) { f, _ := storage.GetFeature(ctx, *obj.ID) return f.IconUrl, nil } 當中呼叫了我們的自定義方法 storage.GetFeature：\n1 2 3 4 5 6 7 func GetFeature(ctx context.Context, featureID int) (*model.RoomFeatureWithData, error) { //... thunk := loaders.FeatureLoader.Load(ctx, DataLoader.StringKey(fmt.Sprintf(\u0026#34;%d\u0026#34;, featureID))) result, err := thunk() //... return result.(*model.RoomFeatureWithData), nil } 重點就是這裡使用到的 loaders.FeatureLoader.Load 方法。\nFeatureLoader 雖為自定義屬性，但是透過 DataLoader 套件提供的 *DataLoader.Loader 建構子 DataLoader.NewBatchedLoader 所創建出，所以本身就具備了 Load 方法。\n在深入探究 Load 方法之前，先釐清一下這個 GetFeature 方法什麼時候會被執行到。回到一開始的案例， 當 Client 進行如下 Query 時：\n1 2 3 4 5 6 7 8 9 10 query { content(hotel_id: 1) { rooms { features { id icon_url } } } } 如果有 n 個 rooms，每個 room 有 m 個 features，總共會執行 n * m 次 IconURL 來取得每個 feature 的 icon URL，也就是執行 m * n 次 GetFeature。而在每個 GetFeature 方法當中又呼叫了 loaders.FeatureLoader.Load 方法，透過回傳的函數取得 feature 資料。\n單純以使用上的角度，可以把 Load 方法當成是一個黑盒子，當我們向他索取需要的資料時，他就會回傳給我們。\n想像如果這些方法都是同步被執行的，假設第一次傳入 GetFeature 的 feature id 為 1，此時要向 DataLoader 取 id 為 1 的 feature 資料，照理來說應該還沒有辦法取得，因為這時候 DataLoader 尚未蒐集到所有 rooms 的 features，（要搜集完所有 id 才會向資料庫查詢），所以應該會暫時 block 住，等待所有 id 蒐集完後才取得所有資料，才能取得 id 1 的資料。可想而知，這個功能背後一定是有非同步的支持才有可能辦到。\n所以到底 DataLoader 是在什麼時候蒐集到所有 rooms 的 features 每個 id 的？又是在什麼時候呼叫向資料庫查詢的方法？就來看看這個 Load 方法到底做了什麼吧！\n然後因為這個方法有點長，所以我會按照順序分段貼上來，但不會全部貼，比較非核心功能的部分也會暫時省略。有興趣的讀者可以自行去看原始碼。\n首先創建一個接收結果的 channel，以及一個 result 變數，接著試圖到 Loader 的 cache 當中尋找 key 對應的值存不存在，有的話就直接返回值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //github.com/graph-gophers/DataLoader@v5.0.0+incompatible/DataLoader.go func (l *Loader) Load(originalContext context.Context, key Key) Thunk { ctx, finish := l.tracer.TraceLoad(originalContext, key) c := make(chan *Result, 1) var result struct { mu sync.RWMutex value *Result } l.cacheLock.Lock() if v, ok := l.cache.Get(ctx, key); ok { defer finish(v) defer l.cacheLock.Unlock() return v } //...下面續 } 返回值是 Thunk 類型，其實就是一個這樣形狀的 function：\n1 type Thunk func() (interface{}, error) 接著，當在 cache 當中找不到對應值時，就新建一個 thunk 函數，當中會使用上面建立的 result 變數，如果 result 裡的值為空，就一直等待直到有資料傳進 channel， 然後將 result 的值更新為傳入的 value。最後寫入 cache。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func (l *Loader) Load(originalContext context.Context, key Key) Thunk { // ...接續上面 thunk := func() (interface{}, error) { result.mu.RLock() //上讀鎖，避免在讀取資料時，同時有其他線程想更新該資料 resultNotSet := result.value == nil result.mu.RUnlock() // 釋放讀鎖 if resultNotSet { result.mu.Lock() //上獨占鎖，避免在更新資料時，同時有其他線程想更新該資料 if v, ok := \u0026lt;-c; ok { // block 住直到 c 有 result 傳入 result.value = v } result.mu.Unlock() //釋放獨佔鎖 } result.mu.RLock() defer result.mu.RUnlock() return result.value.Data, result.value.Error } defer finish(thunk) l.cache.Set(ctx, key, thunk) l.cacheLock.Unlock() //...下面續 } 再來，新增一個 batchRequest，並檢查 loader 當中的 curBatcher 存在與否，不存在就創建新的。這個 curBatcher 內部會有執行自定義方法——也就是在 NewBatchedLoader 時傳入的 featureReader.GetFeature 方法——的邏輯。\n接著另開一個 goroutine 執行 curBatcher 的 batch 方法之後，又開了一個 goroutine 執行 loader 的 sleeper 方法。\n然後把 batchRequest 傳入到了 curBatcher 的 input channel，最後回傳 thunk 函數：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 type batchRequest struct { key Key channel chan *Result } type batcher struct { input chan *batchRequest batchFn BatchFunc //... } func (l *Loader) Load(originalContext context.Context, key Key) Thunk { //...接續上面 // req 包含了要查詢的 key 和 等待接收結果的 channel req := \u0026amp;batchRequest{key, c} l.batchLock.Lock() if l.curBatcher == nil { l.curBatcher = l.newBatcher(l.silent, l.tracer) go l.curBatcher.batch(originalContext) l.endSleeper = make(chan bool) go l.sleeper(l.curBatcher, l.endSleeper) } l.curBatcher.input \u0026lt;- req // 如果有額外設定 batchCap，可以限制一次最多可以接受的 req 數量 if l.batchCap \u0026gt; 0 { // 但我們並沒有設定，所以 batchCap 為 0，不會進入這邊 //... } l.batchLock.Unlock() return thunk } 這時，發現邏輯進到了 curBatcher.batch 方法當中，所以緊接著來看這段方法：\n逐一接收 input 的資料之後，終於看到了執行 b.batchFn(ctx, keys) 也就是我們自定義的資料庫查詢方法！ 然後就是把查詢到的資料，依序放入每個 request 的 channel，再關閉 channel，如此一來 thunk 函數當中等待該 channel 傳回 result 那一行就會取得值而繼續往下執行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func (b *batcher) batch(originalContext context.Context) { var ( keys = make(Keys, 0) reqs = make([]*batchRequest, 0) items = make([]*Result, 0) panicErr interface{} ) // keys 的順序 等同 reqs 的順序 for item := range b.input { keys = append(keys, item.key) reqs = append(reqs, item) } ctx, finish := b.tracer.TraceBatch(originalContext, keys) defer finish(items) func() { // ... items = b.batchFn(ctx, keys) // 執行自定義的資料庫查詢方法 }() // ... // 因為自定義方法當中也有依照 keys 的順序回傳 result，且 keys 的順序 等同 reqs 的順序 // 所以這樣放入順序不會亂 for i, req := range reqs { req.channel \u0026lt;- items[i] close(req.channel) } } 但是別忘了，b.input 也是一個 channel，這邊又使用了 for..range 語法來遍歷 channel，照理來說，除非別的 goroutine 當中有把這個 channel 給關了，否則應該會造成 deadlock 才對。而在哪裡會將 input 這個 channel 關閉呢？\n總共有兩個地方都在 Load 方法當中，一個是當 l.batchCap \u0026gt; 0 時，如果符合指定條件(執行的 req 數量等於 batchCap 數量時)，會呼叫 l.curBatcher.end() 關閉 input chan。\n1 2 3 4 5 6 7 8 if l.batchCap \u0026gt; 0 { //... if l.count == l.batchCap { l.curBatcher.end() // 直接終止接收 req，不再繼續等待 close(l.endSleeper) // 關閉等待特定一段時間的 channel l.reset() } } 另一個是位於 go l.sleeper(l.curBatcher, l.endSleeper) 這一行，所以還得再看一下這個方法做了什麼才行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (l *Loader) sleeper(b *batcher, close chan bool) { select { // 只有在 Load 方法中進入 `l.batchCap \u0026gt; 0` 的 if 區塊時，會對 close channel 傳送訊號 // 這邊收到訊號表示已經提前關閉了 input channel，也不需繼續等待下去 case \u0026lt;-close: return case \u0026lt;-time.After(l.wait): } l.batchLock.Lock() b.end() // \u0026lt;-----here //... } func (b *batcher) end() { if !b.finished { close(b.input) b.finished = true } } 可以看到，當等待時間一到(time.After(l.wait)收到訊號後)，就會往下執行到 b.end()，也就是關閉 input channel 的方法，而等待的時間 l.wait 預設值是 16ms：\n1 2 3 4 5 6 7 8 func NewBatchedLoader(batchFn BatchFunc, opts ...Option) *Loader { loader := \u0026amp;Loader{ batchFn: batchFn, inputCap: 1000, wait: 16 * time.Millisecond, // \u0026lt;-----here } //... } 也就是說，如果 loader 的 input channel 在 16ms 之後都沒有再收到 request 的話，就會自動關閉了。\n總結 看完以上的原始碼之後，算是揭開了 DataLoader 的黑盒子，理解了它的運作原理。最後再重點整理一下 Dataloader 運作的流程：\n當第一次調用 loader 的 Load 方法時，loader 內部會開啟一個 input channel 來接收查詢資料的 request，並開始等待 request 傳入。 每次調用 Load 方法時，都會建立一個 request（裏面包含 key 和一個接收查詢結果的 channel）並將其傳入 input channel。 Load 方法返回一個匿名函數，函數內部如果沒有可以立即返回的結果，會試圖從 request channel 中取值，因此在尚未有值送入 channel 之前會暫時阻塞。 loader 的 input channel 會等待一段時間（預設為 16ms），時間一到就關閉接收 request。（如果有設定接收 request 的最大數量，也有可能提前關閉） input channel 關閉後，就會將所有搜集到的 request keys 傳給自訂批次處理方法，取得所有資料（為 key - value 形式）。 資料載入完成後，將這些資料依照 key 推進對應的 request channel，接收到該 channel 回傳值的匿名函數就會停止阻塞，將結果緩存後，回傳給 client。 ","date":"Jun 04","permalink":"//localhost:1313/posts/golang-graphql-dataloader-2/","tags":["GraphQL","Golang"],"title":"GraphQL Dataloader 在 Golang 當中的打開方法與原理解析（下）"},{"categories":null,"contents":" The Problem 使用 GraphQL 時，遇到以下的查詢：\n1 2 3 4 5 6 7 8 9 10 11 12 13 query { content(hotel_id: 1) { rooms { features { id icon_url text { zh_tw } } } } } 在資料的關聯上，content 底下有許多 rooms，每個 room 底下都有多個 features。但在資料表結構上，room 有一個 content_id 欄位，以及一個 features 欄位，裏面儲存了所有 features 的 id。\n而現在 Client 希望，當 query features 時如果夾帶了 icon_url 或 text 欄位，server 必須多回傳 feature 的這兩個欄位。也就是在 room.feature 的 resolver 的這兩個方法當中：\n1 2 3 4 5 6 7 8 9 func (r *roomFeatureResolver) IconURL(ctx context.Context, obj *model.RoomFeature) (*string, error) { // maybe query feature data from DB by obj.id ...? return f.IconUrl, nil } func (r *roomFeatureResolver) Text(ctx context.Context, obj *model.RoomFeature) (*model.I18nString, error) { // maybe query feature data from DB by obj.id ...? return f.Text, nil } 都需要向 DB 取得 feature 資料。\n但這麼一來，只要有 n 個 rooms，m 個 feature，就得 query n * m * 2(取得 icon_url 和 text 2 個欄位) 次，嗯..非常熟悉的 N+1 問題。 要解決這個問題，GraphQL 官方有提供一個方法，那就是使用 DataLoader。\n什麼是 Dataloader？ DataLoader 是 GraphQL 官方提供的一個套件，主要用於解決資料載入時的效能問題。透過將多個請求收集到批次中，然後一次性獲取結果，從而減少重複的查詢或計算。 具體而言，DataLoader 有以下特點：\n以下所提到的「請求」都是指在同一個 API Request 生命週期當中，對同一資料的讀取請求。\n批次處理：DataLoader 會將一段時間內或一定數量的請求進行批次處理載入數據，以減少資料庫的查詢次數和計算成本。\n緩存：DataLoader 內部使用緩存機制，將已經載入的資料暫存在記憶體中。當下次請求需要相同的資料時，可以直接從緩存中返回，避免再次查詢資料庫。(但這些緩存數據只會存在於同一個 API Request 的生命週期當中，當 Request 結束後就會被清除)\n避免重複載入：DataLoader 會確保同一個資料只被載入一次，即使同一時間有多個請求要求載入相同的資料，也只會執行一次載入操作。\n但因為官方套件只有 nodejs 版本，其他語言的話官方是表示留給開發者們自己去實現\u0026hellip;\n\u0026ldquo;DataLoader is provided so that it may be useful not just to build GraphQL services for Node.js but also as a publicly available reference implementation of this concept in the hopes that it can be ported to other languages.“\n當然使用 Golang 的我們很幸運地還是可以繼續站在巨人的肩膀上，在 gqlgen（一個提供快速搭建 GraphQL Server 的套件）的文件當中，就直接端出了這個 Golang 版本的套件：graph-gophers/DataLoader。所以下所討論的使用方法以及原始碼，都是會以這個套件的內容為主。\n使用 Dataloader 那麽就來透過 DataLoader 實現我們的需求吧！\n預期達到的效果是：將 Query 當中所有 rooms.features 的 id 都搜集起來，一次向資料庫發送查詢，取得所有 feature 資料後，將其暫存在記憶體，當需要特定 id 的 feature 資料時便從中取出回傳。\n雖然使用方式在剛剛提到的 gqlgen 官方文件所提供的範例當中都已經寫得很清楚，但下面還是會完整呈現，補充當中幾個方法跟參數的關係，以便在後續的原始碼閱讀中可以更容易理解：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 // my_repo/graph/storage/storage.go package storage type ctxKey string const ( loadersKey = ctxKey(\u0026#34;dataloaders\u0026#34;) ) type FeatureReader struct { featureRepo model.FeatureRepository // 將向DB查詢的部分封裝到 Repository 當中 } // 實際上會被 dataloader 所呼叫，用來一次取得所有 features 的方法 // 這邊的參數 keys 的來源是下方另一個同名的自定義方法當中，呼叫了 dataloader 的 Load 方法 // 而 Load 方法都會接收一個 key 參數 // 當搜集完成所有的 keys 後就會被傳進這邊來 func (u *FeatureReader) GetFeature(ctx context.Context, keys dataloader.Keys) []*dataloader.Result { featuresIDs := make([]int, len(keys)) for ix, key := range keys { featureID, _ := strconv.Atoi(key.String()) featuresIDs[ix] = featureID } featuresById, err := u.featureRepo.GetFeaturesByIDs(ctx, featuresIDs) // 實際向DB取資料的方法 if err != nil { return nil } // 必須將資料的順序按照 keys 的順序排列 output := make([]*dataloader.Result, len(keys)) for index, featureKey := range keys { feature, ok := featuresById[featureKey.String()] if ok { output[index] = \u0026amp;dataloader.Result{Data: feature, Error: nil} } else { err := fmt.Errorf(\u0026#34;feature not found %s\u0026#34;, featureKey.String()) output[index] = \u0026amp;dataloader.Result{Data: nil, Error: err} } } return output } type Loaders struct { FeatureLoader *dataloader.Loader } // 待會會在主程式裏面呼叫，實例化所有 loaders 以便傳入 middleware 當中 func NewLoaders(MySqlFeatureRepository model.FeatureRepository) *Loaders { featureReader := \u0026amp;FeatureReader{ featureRepo: MySqlFeatureRepository, } loaders := \u0026amp;Loaders{ //新增一個 Loader 並傳入自定義的批次處理方法 FeatureLoader: dataloader.NewBatchedLoader(featureReader.GetFeature), } return loaders } // 透過 middleware 將 loaders 注入到 context 裏面 // 以利其他地方可以透過同一個 ctx 物件取得 loader（一個 API Request 當中會有一個 ctx 物件） func Middleware(loaders *Loaders, next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { nextCtx := context.WithValue(r.Context(), loadersKey, loaders) r = r.WithContext(nextCtx) next.ServeHTTP(w, r) }) } // 將 loaders 從 context 當中取出的 helper method func For(ctx context.Context) *Loaders { return ctx.Value(loadersKey).(*Loaders) } // 會在 resolver 當中被呼叫，只要傳入 feature id 就會回傳在 dataloader 當中準備好的對應資料 func GetFeature(ctx context.Context, featureID int) (*model.RoomFeatureWithData, error) { loaders := For(ctx) // 這邊所傳入 Load 的第二個參數，也就是上面自定義方法 FeatureReader.GetFeature 註解當中所提到 // 每個傳進 Load 的第二個參數，也就是 key // 都會被搜集下來，直到所有 keys 搜集完畢後，就會觸發 FeatureReader.GetFeature 方法 // 並將所有搜集的 keys 傳入該方法 thunk := loaders.FeatureLoader.Load(ctx, dataloader.StringKey(fmt.Sprintf(\u0026#34;%d\u0026#34;, featureID))) // 留意 key 必須為字串類型 result, err := thunk() if err != nil { return nil, err } return result.(*model.RoomFeatureWithData), nil } 接著，到 resolver 當中，將取得資料的邏輯改成呼叫 stroage.GetFeature 方法：\n1 2 3 4 5 6 7 8 9 func (r *roomFeatureResolver) IconURL(ctx context.Context, obj *model.RoomFeature) (*string, error) { f, _ := storage.GetFeature(ctx, *obj.ID) return f.IconUrl, nil } func (r *roomFeatureResolver) Text(ctx context.Context, obj *model.RoomFeature) (*model.I18nString, error) { f, _ := storage.GetFeature(ctx, *obj.ID) return f.Text, nil } 然後在主程式當中（或是定義路由的檔案），加上 middlerware：\n1 2 3 4 router.Use(func(next http.Handler) http.Handler { // 每次 request 都有自己的 dataloader return storage.Middleware(storage.NewLoaders(featureRepo), next) }) 至此，不管往後總共有幾個 features，都只會執行一次的資料庫查詢，解決了 N+1 問題。 礙於篇幅有點太長，想說拆成上下兩篇比較好閱讀，所以分析 Dataloader 原始碼的部分，就留到下一篇了～\n","date":"Jun 04","permalink":"//localhost:1313/posts/golang-graphql-dataloader-1/","tags":["GraphQL","Golang"],"title":"GraphQL Dataloader 在 Golang 當中的打開方法與原理解析（上）"},{"categories":null,"contents":" 前言 上一篇文章 Golang 資料庫(整合)測試 當中提到了在使用真實資料庫作為測試資料庫時，還可以使用 testcontainers 讓我們能夠在測試當中直接操作 Docker Container，去建立測試時需要的資料庫環境。這樣一來，也不用像一開始那樣，得另外手動配置一個專門拿來跑測試用的資料庫，將測試整合到 CI/CD 流程上時也比較方便。\n然後應該是不會有 Part 3 啦。 Testcontainers 簡介 Testcontainers 為多種語言提供套件（Golang、Java、Python 等等），開發人員可以透過該套件所提供的 API，在程式當中建立和清除基於容器的依賴項，以進行自動化整合測試。\n所以就延續使用上篇文章當中的範例，把它改成使用 Testcontainers 的版本吧！\n使用 Testcontainers Requirement 首先必須先確保環境當中有安裝 Docker，狀態為 running，且使用者要有權限可以執行 docker 指令。 不同的作業系統會有不同的建議版本和注意事項，可以參考官方文件。\nnote: 原本在 local 跑，電腦是 Mac 又是 M1 晶片，遇到一堆環境問題快被搞瘋，後來索性放棄，改成在 linux 主機上面跑就都一切正常QQ\n安裝 Testcontainers for Go 包 go get github.com/testcontainers/testcontainers-go 安裝 MySql Module 包 由於我們使用的 MariaDB 為 MySql 旁系血親，所以可以安裝官方提供的 MySql Module 包，直接用包提供的 API 可以再多省下一些程式碼：\ngo get github.com/testcontainers/testcontainers-go/modules/mysql 調整程式碼 上回我們將重置資料庫的步驟放在 suite 的 setup 當中，那我們勢必得在這個動作之前先準備好資料庫，也就是要先把 MariaDB container 起起來：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 import ( \u0026#34;github.com/testcontainers/testcontainers-go\u0026#34; \u0026#34;github.com/testcontainers/testcontainers-go/wait\u0026#34; testcontainermysql \u0026#34;github.com/testcontainers/testcontainers-go/modules/mysql\u0026#34; ) // 添加了幾個屬性到 struct 裡面 type MysqlRepoTestSuite struct { suite.Suite dbUser string dbPassword string dbName string dbHost string dbPort string mariadbC *testcontainermysql.MySQLContainer ctx context.Context } func (suite *MysqlRepoTestSuite) SetupSuite() { // ------開始啟動 container 的作業------ suite.ctx = context.Background() mariadbC, err := testcontainermysql.RunContainer( suite.ctx, testcontainers.WithImage(\u0026#34;mariadb:10.5\u0026#34;), testcontainermysql.WithPassword(suite.dbPassword), testcontainermysql.WithDatabase(suite.dbName), testcontainers.WithWaitStrategy( wait.ForLog(\u0026#34;mysqld: ready for connections.\u0026#34;). WithOccurrence(2). WithStartupTimeout(2*time.Minute), ), ) if err != nil { log.Fatal(\u0026#34;Failed to start MariaDB container: \u0026#34;, err) } suite.host, err = mariadbC.Host(suite.ctx) // 取得 container 的 host if err != nil { log.Fatal(\u0026#34;Failed to get MariaDB container host: \u0026#34;, err) } // 將 container 3306 port 映射到主機上，並取得映射到主機上的 port // (等同下 docker run 指令時的 -P {主機port}:{container port} 操作) mappedPort, _ := mariadbC.MappedPort(suite.ctx, \u0026#34;3306/tcp\u0026#34;) suite.container = mariadbC suite.port = strconv.Itoa(mappedPort.Int()) if err != nil { log.Fatal(\u0026#34;Failed to get MariaDB container port: \u0026#34;, err) } _, err = suite.freshDatabase() if err != nil { panic(err) } } 傳入 testcontainermysql.RunContainer() 的參數除了 ctx 之外都是選填，分別解釋上面傳入各個參數的意義：\ntestcontainers.WithImage(\u0026quot;mariadb:10.5\u0026quot;) 指定使用 mariadb 10.5 版本的 docker image（不傳入該參數的話，預設會抓取 mysql:8 的 docker image）\ntestcontainermysql.WithPassword(suite.dbPassword) 指定啟動 container 時傳入的環境變數 MYSQL_PASSWORD（不傳入的預設值是 test）\ntestcontainermysql.WithDatabase(suite.dbName) 指定啟動 container 時傳入的環境變數 MYSQL_DATABASE，建立一個名為 suite.dbName(變數) 的 database（不傳入的預設值是 test）\ntestcontainers.WithWaitStrategy(wait.ForLog(\u0026quot;mysqld: ready for connections.\u0026quot;).WithOccurrence(2).WithStartupTimeout(2*time.Minute)) 由於下建立 container 的指令之後，需等待 container 完全啟動，才能保證後續的使用可以正常地連接上 container，因此這個參數是讓我們可以設定等待的策略。分別解釋鏈的各個方法意義：\nwait.ForLog()：程式會被 blocking 住，直到 container 當中特定的 log 出現後，才繼續往下執行 WithOccurrence()：指定 log 必須出現的次數 WithStartupTimeout()：指定等待的超時時間 用人話來總結這一行的操作： 等待 log 當中出現 mysqld: ready for connections.這段文字 2 次之後才繼續往下執行，如果 2 分鐘之內沒等到的話就跳 timeout 錯誤。\n接著，就是要記得在 suite 的 teardown 當中，關閉 container 釋放資源：\n1 2 3 4 5 6 func (suite *MysqlRepoTestSuite) TearDownSuite() { err := suite.mariadbC.Terminate(suite.ctx) if err != nil { panic(err) } } 最後就可以來跑看看測試了：\ngo test 成功囉🎉\n小結 其實使用的方式滿簡易的，概念上也不難，就是在 setup 當中最一開始多一個「啟動資料庫 Server 的 Docker Container」以及最後 teardown 時「關閉 container」的步驟而已，後面就可以繼續原本的流程(重置資料庫、開啟連線\u0026hellip;等等)，但比較會遇到問題的部分可能會是在環境配置以及 API 的使用，因為官方文件的範例都沒有到很完整，使用時會需要摸索一陣子，因此才特別寫一篇筆記記錄。\n最後附上完整的程式碼範例： https://gist.github.com/linxinemily/276905e0145218538cb0be3a79a36153\n","date":"May 17","permalink":"//localhost:1313/posts/golang-database-testing-with-testcontainer/","tags":["Golang","Testing"],"title":"Golang 的資料庫(整合)測試 Part 2 - 使用 Testcontainers"},{"categories":null,"contents":"\nTL;DR 本文記錄了探索在 Golang 當中撰寫資料庫整合測試的過程及方法。包含幾個重點的討論：\n進行資料庫測試時，該使用真實的測試資料庫或是測試替身(Test Double)？ 使用測試資料庫的話，該如何重置資料庫狀態，才能避免不同測試方法之間的資料相互影響？ 最後提供讓不同測試方法之間資料不互相影響，並能平行跑測試的實作方法 前言 有經驗的工程師都知道寫測試對於軟體開發的重要性，而當中最基本的就是單元測試。狹義或者說比較嚴格定義的單元測試，如果以 Clean Architechture 的觀點來看，通常是針對 Domain Layer 以及 Application(Use Case) Layer ，也就是不涉及外部服務或套件/架等等的測試。但對於一些小型專案來說，Domain 邏輯通常不多，大部分都是對資料庫的 CRUD 操作，又或者使用的框架原本就把 ORM 跟 Model 綁死在一起，框架提供的測試集成 API 也是直接預設好對真實資料庫的連接，整個專案可能幾乎沒有幾個狹義的單元測試了。\n不過硬是要畫分出單元測試或者整合測試其實沒什麼意義，這邊只是想要稍微點出一道現實，在和資料庫高度掛鉤或者所謂資料密集型的服務底下，資料庫測試勢必是極重要的一環。\n然而在 Golang 當中，並沒有像是 Spring Boot or Laravel 這種包山包海的框架（似乎也不太可能出現，畢竟違反了 Golang 的設計哲學），測試的部分，雖然標準庫有提供一個測試套件，但僅是對於單元測試以及性能測試的輔助，至於資料庫測試？得自己想辦法。\n還是可以找得到對於資料庫測試的輔助套件，但因爲泛用性沒有到非常廣，且實現資料庫測試的方法其實也並不難，所以就沒有特別去使用，這邊也不多加介紹。\n情境概述 參考 Clean Architecture 的架構，專案當中有劃分 Domain、Application、Adapter 以及 Port Layer。而在 Domain Layer 當中我們定義了 UniqidRepository 介面：\n1 2 3 4 //domain layer type UniqidRepository interface { GetUniqidsWithDevicesFilterByUniqId(ctx context.Context, uniqid string) ([]*Uniqid, error) } 這個介面會由 Adapter Layer 當中不同的 Repository 去實作，在這邊我們定義一個 PostgresUniqidRepository ，實現 UniqidRepository 介面，並且內嵌一個資料庫連線物件(使用 了 gorm 提供的 struct)：\n1 2 3 4 5 6 7 8 9 10 11 12 type PostgresUniqidRepository struct { db *gorm.DB } func (u *PostgresUniqidRepository) GetUniqidsWithDevicesFilterByUniqId(ctx context.Context, uniqid string) ([]*domain.Uniqid, error) { ctx, cancel := context.WithTimeout(ctx, 30*time.Second) defer cancel() // to retrieve data from DB by GORM... return uniqids, nil } 資料庫測試的選擇：測試替身 VS 真實資料庫 為了要撰寫 PostgresUniqidRepository 的測試，我們會需要依賴一個 db 物件，那這時候應該連接一個真實的測試資料庫，還是使用測試替身(Test Double)呢？先來看看這兩者各自的優缺點：\n使用測試替身 測試替身是一個模擬資料庫行為的物件或程式，用來替代真實的資料庫連接。方法就是將原本實作連接真實資料庫的物件藉由依賴注入抽換成測試替身（之所以可以抽換，通常是因為有定義了一個介面，不論是連接真實資料庫的物件或是測試替身，都會去實現這個介面）透過測試替身去模擬資料庫的行為和回傳值。\n在 Golang 當中，如果是使用 SQL 類型的資料庫，官方標準庫就有定義了 sql.DB 介面，也有相關的 library 像是 go-sqlmock 當中就提供了實現該介面方法的測試替身，讓開發者能在測試時能夠檢查所執行的 SQL 語句是否如預期，並模擬資料庫的回傳值。如果是使用其他類型的資料庫，例如 AWS 的 DynamoDB，其提供的 client sdk 當中也有包括 dynamodb 介面，也是相同的概念。\n優點： 提供了較高的測試控制，容易模擬錯誤情境(ex: 模擬資料庫連接失敗)。 由於不需要真實的資料庫連接，測試速度可能會更快。 缺點： 可能無法完全模擬真實資料庫的行為，因此測試結果可能與實際運行時的行為不一致。 需要額外的開發和維護工作，包括模擬資料庫的行為和維護測試替身的狀態，可能增加開發和維護成本。 剛剛有提到說包山包海的框架中，例如 Laravel，官方是沒有直接提供使用測試替身資料庫的選項，不過有 Memory 資料庫(sqlite)，這又是另一種資料庫測試的選擇，但這邊不特別介紹，暫且把他歸類在使用真實資料庫的範疇，因為依然是依賴外部服務。\n使用真實資料庫 一個實際運行在主機或容器上的資料庫，通常專門 for 測試用。\n有網友補充，還可以使用像是 testcontainers-go 這種工具，讓開發者可以透過呼叫其 API 來管理和使用 Docker 容器，進行測試和集成測試。能夠在測試當中更方便地管理資料庫依賴。介紹與用法可參考下一篇筆記。\n優點： 提供更接近實際運行環境的測試，測試結果更加真實可靠。 可以測試到真實資料庫的特定行為、效能等方面的問題，更全面地驗證系統的品質。 缺點： 測試結果可能受到真實資料庫狀態和環境的影響，較難以控制測試情境。 可能會因為資料庫中的變動而導致測試結果不穩定，像是不同測試案例之間的資料相互影響，需另外透過適當地調整測試順序、編寫清理腳本或確保不同測試案例使用資料的獨立性等方法來避免。 所以到底要用使用測試替身還是真實資料庫呢？\n回到一開始範例的情境，有一個 Repository 專門用來連接 Postgres 資料庫，同時又用了 gorm 這個 ORM 套件包裝真實的 SQL 語法。如果要使用測試替身的話，可以借助 go-sqlmock 這個套件。但仔細想想，以 GetUniqidsWithDevicesFilterByUniqId 這個方法來看，僅有的邏輯就是取得所有/被過濾的 Uniqid 資料而已，如果又用了測試替身，那麽這個測試就變成只剩下檢查 SQL 語法有沒有組對。這樣算是一個有用的測試嗎？\n以這個針對 Repository 測試的情境而言，是否有確實從資料庫中取出正確的資料，才是我們真正想要驗證的事情。因此，我認為使用真實資料庫會是比較適合的做法。\n查詢資料的過程中，有看到一篇由 Github 工程師所撰寫的部落格文章，當中也有提到，”You need to actually test your SQL code.”\n資料庫整合測試：重置資料庫狀態的方式 如果要進行連接實際資料庫的整合測試，為了避免每個測試彼此之間的資料互相影響，通常會在每次跑測試之前先重置資料庫狀態。重置資料庫狀態的方式有很多種，參考了手邊最常使用的 Laravel 框架，當中有提供許多協助在測試時重置資料庫狀態的 Trait，都是平常開箱即使用的方法：\nDatabaseMigration：在每個測試方法執行之前，先刪除資料庫中的所有資料表，並重新 migrate，等該測試方法跑完後，再 rollback 所有 migrations。 DatabaseTransactions：在每個測試方法執行之前，開始一個 transaction，等該測試方法跑完後，再將 transaction rollback，回復到資料庫原本的狀態。 RefreshDatabase：在每個測試方法執行之前，(非使用內存資料庫的狀況下)會先判斷資料庫的狀態是否已經 migrate 過，如果還沒就刪除資料庫中的所有資料表、重新 migrate，並將 migrate 狀態標示為已經 migrate 過 ，接著繼續執行和 DatabaseTransaction 相同的行為。 從這些 Laravel 所提供的 Trait 當中，大概可以整理出兩個方案：\n在每次跑測試方法之前，先跑 migration，等測試方法執行完畢後，再 rollback migration。 好處就是簡單方便，但由於需要在每個測試方法當中都跑一遍 migration 再 rollback，連接真實資料庫的情況下，速度會比較慢。（所以大多是使用內存資料庫如 sqlite 時才會使用這個方法） 在每次跑測試方法之前先開啟一個資料庫交易(begin transaction)，等測試方法執行完畢後，再回滾交易(rollback transaction)。 不需要跑每個測試方法時都真的把整個資料庫重置，而是利用交易的特性，將每個測試當中對資料庫進行的操作都視為原子性的操作，執行速度較快。但需另外注意的是，不同測試方法如果都對同一筆或同一區間的資料做操作，可能會產生非預期的資料，進而影響到測試的結果。所以使用這個方法時，通常會在每個測試當中創建該測試需要用到的資料，而非和其他測試共享資料，如此一來，可以降低測試之間相互影響的風險，確保每個測試的獨立性。 但由於要使用真實資料庫來測試，以我們的情境來看，使用第二種方式會是比較適當的選擇。\n其實重置資料庫狀態的方式不只這幾種，但 Laravel Trait 所提供的方式已經能滿足我們基本的需求，就不再額外探討。\n實作資料庫整合測試 總算進入到實作測試的部分了！\n在這邊會使用到幾個第三方套件來輔助測試以及資料庫的連接：\ntestify/suite：testify 測試框架當中的 suite package 方便用來對整體/分組/單獨的測試方法創建 setup 以及 teardown 方法。只要內嵌suite.Suite struct，就可以藉由複寫以下方法，來實現為不同的測試行為加入前/後置處理： SetupSuite() ：執行 suite 當中所有測試方法之前的前置處理 TearDownSuite() ：執行 suite 當中所有測試方法之後的後置處理 SetupTest()：執行 suite 當中每個測試方法之前的前置處理 TearDownTest() ：執行 suite 當中每個測試方法之後的後置處理 go-migrate：使用 CLI 或是在程式當中呼叫特定方法執行定義好的 migration 檔案。 gorm：Golang 當中著名的 ORM 框架。由於 Repository 當中使用了該套件存取資料庫，所以執行 Repository 方法時需要使用到。 我們可以在 suite 的 setup 當中，先重置資料庫並開啟一個連線。然後將每個測試方法都用一個 transaction 包住（在開始前先 begin TX、結束後 rollback TX），最後在 suite teardown 時關閉資料庫連線：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 type PostgresRepoTestSuite struct { suite.Suite db *gorm.DB tx *gorm.DB } func (suite *PostgresRepoTestSuite) SetupSuite() { // 重置資料庫，先把資料庫 rollback 或整個 reset 後再跑 migrations // 這邊的 migrations 應僅包含 DDL，並不會塞入任何一筆資料 _, err := freshDatabase() if err != nil { panic(err) } // 開啟一個資料庫連線並暫存，以便讓 suite 底下每個測試方法共用 suite.db = openDatabaseConnection() } func (suite *PostgresRepoTestSuite) TearDownSuite() { sqlDB, _ := suite.db.DB() sqlDB.Close() // suite 底下所有測試方法跑完後，關閉資料庫連線 } func (suite *PostgresRepoTestSuite) SetupTest() { suite.tx = suite.db.Begin() // 使用暫存的 DB 連線物件，開啟一個 transaction } func (suite *PostgresRepoTestSuite) TearDownTest() { suite.tx.Rollback() // 回滾 transaction } func TestPostgresRepoTestSuite(t *testing.T) { suite.Run(t, new(PostgresRepoTestSuite)) // 執行 suite 底下所有測試方法 } // 實際的測試方法，必須為 suite 的 receiver func (suite *PostgresRepoTestSuite) TestGetUniqidsWithDevicesFilterByUniqId() { // 主要的測試邏輯 // ... } 在 PostgresRepoTestSuite 中， db 和 tx 變數是由 suite 底下的每個測試方法所共用的。在單一執行緒下執行測試時，這並不會造成任何問題。但如果要平行執行測試，這些方法在同一時間可能會競爭同一個變數，導致資源競爭的情況，進而影響測試結果的正確性。此外，這些方法執行時都是使用同一個資料庫連線，可能也會產生意外的錯誤。\n於是我們可以改成在每個測試方法當中，都開啟專屬的資料庫連線，並創建獨立的變數保存連線實體，順便模擬平行跑測試時的場景：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 type PostgresRepoTestSuite struct { suite.Suite } func (suite *PostgresRepoTestSuite) SetupSuite() { _, err := freshDatabase() if err != nil { panic(err) } } // 覆寫了原本內嵌的 suite.Suite 預設 Run 方法 // 以便為每個方法創建獨立的資料庫連線物件 // 同時使用標準庫 *testing.T 提供的 Run 方法 wrap 起來，待會就能夠平行地執行這些子方法 func (suite *PostgresRepoTestSuite) Run(t *testing.T, method string, fn func(t *testing.T, tx *gorm.DB)) { t.Run(method, func(t *testing.T) { var db *gorm.DB var tx *gorm.DB defer func() { sqlDB, _ := db.DB() sqlDB.Close() }() defer func() { tx.Rollback() }() db = openDatabaseConnection() tx = db.Begin() fn(t, tx) }) } func TestPostgresRepoTestSuite(t *testing.T) { t.Parallel() // 使用 goroutine 同時運行所有測試方法 suite.Run(t, new(PostgresRepoTestSuite)) } func (suite *PostgresRepoTestSuite) TestGetUniqidsWithDevicesFilterByUniqId() { // 呼叫剛剛覆寫的 Run 方法，將原本測試邏輯包裝成 function 做為參數傳入 suite.Run(suite.T(), \u0026#34;TestGetUniqidsWithDevicesFilterByUniqId\u0026#34;, func(t *testing.T, tx *gorm.DB) { // 主要的測試邏輯 // ... }) } 但要注意的是，即使每個測試方法都使用各自的資料庫連接，如果兩個測試方法都嘗試同時對同一條資料進行存取，或者對某個範圍進行存取，也有可能存在資料庫層面的事務競爭。不過如果每個測試方法都只是操作自己創建的資料，迸發測試應該是安全的。\n小結 重點整理如下：\n如果要測試的 function 都和資料庫互動為主，通常會建議使用真實資料庫測試而非資料庫替身。\n重置資料庫狀態可以藉由在每個測試方法執行前/後分別 run/rollback migrations 或開啟/回滾一個資料庫交易。使用交易通常會更省資源，但必須確保每個測試方法當中所使用資料的獨立性。\n實作測試方法：\n在 suite 的 setup 當中，重置整個資料庫後再跑 migration（僅包含 DDL，此時資料庫沒有任何一筆資料） 在 suite 底下的每個測試法方當中按照順序執行： 開啟獨立的 DB 連線 開始交易 運行測試邏輯（當中才建立所需的資料） 回滾交易 關閉 DB 連線 如此一來，DB 連線和資料都不會互相干擾，也可以平行跑測試。\n","date":"Apr 23","permalink":"//localhost:1313/posts/golang-database-testing/","tags":["Golang","Testing"],"title":"Golang 的資料庫(整合)測試"},{"categories":null,"contents":"要將 Go 的 struct 轉成 JSON 格式時，通常都會藉由官方提供的標準函式庫 encoding/json 去實現，也會借助在 struct 當中為特定欄位定義 json tag 去標示輸出成 JSON 格式時的命名和規則。在欄位值存在的情況下基本上不會有什麼問題，但如果欄位沒有值，就有可能會輸出非預期結果（簡稱：踩坑）。\n首先必須先釐清一件事，所謂的「沒有值」準確來說是指什麼？nil？空陣列？還是空字串？我們都知道在 Golang 當中，不同類型的資料有著不同的「零值(Zero Value)」，比如 string 的零值是空字串、int 的零值是 0。然而「沒有值」比較偏向一個籠統的說法，也不管程式語言的定義，反正就是沒有資料的意思。又或者說以使用者角度來看，因為不管欄位資料裡面是空字串或是 NULL，對他們來說就都是沒資料。\n以下會以這個 struct 為範例，分別來看這兩種不同類型(reference v.s. value type)的資料欄位，在面臨沒有資料時會輸出什麼結果。\n1 2 3 4 type Person struct { Name string `json:\u0026#34;name\u0026#34;` Hobbies []string `json:\u0026#34;hobbies\u0026#34;` } Reference Type - Slice 當欄位類型為 slice 的時候，在不同情況下的「沒有值」，轉換出來的結果也會有所不同。\n1.當 Hobbies 是一個已初始化過後的空 slice：\n1 2 3 4 5 6 7 8 9 10 11 12 // 初始化方式一： hobbies := make([]string, 0) // 初始化方式二： // hobbies := []string{} // 都是初始化一個長度/容量皆為 0 的 slice emmie := Person{ \u0026#34;Emmie\u0026#34;, hobbies, } jsonData, _ := json.Marshal(emmie) fmt.Println(string(jsonData)) 輸出：\n1 {\u0026#34;name\u0026#34;:\u0026#34;Emmie\u0026#34;,\u0026#34;hobbies\u0026#34;:[]} 2.當 Hobbies 是一個只有宣告變數，沒有初始化的 slice：\n1 2 3 4 5 6 7 8 var hobbies []string emmie := Person{ \u0026#34;Emmie\u0026#34;, hobbies, } jsonData, _ := json.Marshal(emmie) fmt.Println(string(jsonData)) 輸出：\n1 {\u0026#34;name\u0026#34;:\u0026#34;Emmie\u0026#34;,\u0026#34;hobbies\u0026#34;:null} 之所以會有這種差異是因為在 Golang 中，當宣告一個變數但是沒有初始化值的話，其預設值會是該類型的零值，而對於 slice、map、channel 這樣的類型(reference type)來說，零值是 nil。\n在第一個範例中，slice 變數會被初始化為一個長度及容量皆為 0 的空 slice，而不是 nil。所以 hobbies 在宣告時已經被初始化為一個空的 slice，因此 emmmie 的 hobbies 欄位會是一個空的 slice，它的 JSON 表示就是 []。\n然而，在第二個範例中，hobbies 變數僅有被宣告，所以預設值為 nil，而不是一個空的 slice。在 JSON 轉換期間，nil slice 會被轉換成 JSON 的 null 值。\n如果想在 hobbies 欄位為 null 或空陣列時（也就是 slice 為 nil 或 空 slice 的狀態下），不要輸出該欄位 key，像這樣：\n1 {\u0026#34;name\u0026#34;:\u0026#34;Emmie\u0026#34;} 那就要修改 struct 當中的定義，為 hobbies 加上 omitempty 標籤：\n1 Hobbies []string `json:\u0026#34;hobbies,omitempty\u0026#34;` 統整一下，所以在將 struct 轉換成 JSON 時，如果有欄位的類型是 slice ：\n狀況 輸出 JSON 的值 未初始化（nil slice） null 已初始化（空 slice） [] 未初始化（nil slice）但加上 omitempty 標籤 key 直接消失 已初始化（空 slice）但加上 omitempty 標籤 key 直接消失 可以發現 slice 類型（reference type）的欄位加上 omitempty ，不管其值是 nil（零值） 或是空 slice，key 都會消失。\nValue Type - String 那如果當欄位類型是 string、int 等 value type 呢？\n繼續使用上面的範例 struct，在還沒加上 omitempty tag 時：\n1 2 3 4 type Person struct { Name string `json:\u0026#34;name\u0026#34;` Hobbies []string `json:\u0026#34;hobbies,omitempty\u0026#34;` } 1 2 3 4 emmie := Person{} jsonData, _ := json.Marshal(emmie) fmt.Println(string(jsonData)) 輸出：\n1 {\u0026#34;name\u0026#34;:\u0026#34;\u0026#34;} 如果把 name 也加上 omitempty tag：\n1 2 3 4 type Person struct { Name string `json:\u0026#34;name,omitempty\u0026#34;` Hobbies []string `json:\u0026#34;hobbies,omitempty\u0026#34;` } 輸出：\n1 {} string 未初始化情況下，預設為零值空字串， key 也消失了。\n但如果我們不想讓 key 直接消失，想要輸出 null 的話該怎麼辦？方法是將 struct 當中的 string 改成指標類型 *string （因為指標類型的零值也是 nil）且不需要 omitempty tag：\n1 2 3 4 type Person struct { Name *string `json:\u0026#34;name\u0026#34;` Hobbies []string `json:\u0026#34;hobbies,omitempty\u0026#34;` } 輸出：\n1 {\u0026#34;name\u0026#34;:null} 再統整一下：\n類型 狀況 輸出 JSON 的值 string 未初始化（空字串） \u0026quot;\u0026quot; string 未初始化（空字串）但加上 omitempty 標籤 key 直接消失 *string 未初始化 （nil） null 總結 在不同類型中，根據零值不同，輸出的 JSON 值也不同。 然而在相同類型中，輸出的 JSON 值也有不同的可能性。例如剛剛提到的 slice 類型，初始化後的空 slice 會輸出空陣列，而未初始化為零值的 nil slice 會輸出 null。 omitempty tag 會影響 key 值的存留。 只要注意這幾點，就可以避免在輸出 JSON 時得到非預期的資料類型/結構。\n","date":"Mar 27","permalink":"//localhost:1313/posts/golang-struct-to-json-and-empty-data/","tags":["Golang"],"title":"Golang struct 轉 JSON 遇到欄位沒有值的問題"},{"categories":null,"contents":"最近在研究 oapi-codegen 這套基於 OpenAPI 3.0 自動生成 Go boilerplate 程式的工具，能幫助開發者省下很多撰寫實現 HTTP Server 端口、marshalling 和 unmarshalling 的重複程式碼的時間。當進行系統重構或使用像是文件先行(Documentation-Driven Development)的開發方法時也很適用。 在此紀錄一下餵入 OpenAPI 檔案時遇到的問題。\n問題概述 使用以下 OpenAPI yaml 檔（擷取片段）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 schemas: Response: status: description: 狀態 type: integer example: 200 message: description: 訊息 type: string example: success detail: description: 詳細訊息 type: object example: {} #...more paths: /iot/stations: get: parameters: - name: uniqid in: query description: Uniqid required: false schema: type: string responses: \u0026#39;200\u0026#39;: description: OK content: application/json: schema: type: object properties: data: type: object properties: items: type: array #...more message: $ref: \u0026#39;#/components/schemas/Response/message\u0026#39; status: $ref: \u0026#39;#/components/schemas/Response/status\u0026#39; 跑生成代碼的指令時\n1 $ oapi-codegen -package main openapi.yaml \u0026gt; openapi.gen.go 會噴這個錯誤\nerror generating code: error creating operation definitions: error generating response definitions: error generating request body definition: error generating Go schema for property \u0026#39;message\u0026#39;: error turning reference (#/components/schemas/Response/message) into a Go type: unexpected reference depth: 5 for ref: #/components/schemas/Response/message local: true 看了一下原始碼，發現他只能解析四層的 $ref path：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // https://github.com/deepmap/oapi-codegen/blob/master/pkg/codegen/utils.go#L322-L332 // refPathToGoType returns the Go typename for refPath given its func refPathToGoType(refPath string, local bool) (string, error) { if refPath[0] == \u0026#39;#\u0026#39; { pathParts := strings.Split(refPath, \u0026#34;/\u0026#34;) depth := len(pathParts) if local { if depth != 4 { // \u0026lt;---------here! return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;unexpected reference depth: %d for ref: %s local: %t\u0026#34;, depth, refPath, local) } } else if depth != 4 \u0026amp;\u0026amp; depth != 2 { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;unexpected reference depth: %d for ref: %s local: %t\u0026#34;, depth, refPath, local) } 也就是說，只有長這樣的 path 才能被順利解析：\n#/components/responses/Baz 而在上面的 yaml 當中的 path 已經到第五層 #/components/schemas/Response/message ，因此會報錯。\n後來發現，這種寫法不是合法的 OpenAPI 格式的寫法（但用 redoc 可以 build 出來），因為當跑 lint 的時候會報錯。\n如果要改成合法的格式，首先 schema 的地方要在每個 Object 底下增加 properties 屬性：\n1 2 3 4 5 6 7 schemas: Response: properties: # \u0026lt;-------- add this status: description: 狀態 type: integer example: 200 然後 $ref path 要改成 #/components/schemas/Response/properties/message 才能通過 linter 檢查。\n但即使改成了合法格式，在用 oapi-codegen 生成代碼時還是會報錯。因為 path 總層數變成 6 層，依然無法被解析。\n解決方法 1. 改成只使用四層的 $ref 像這樣：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 schemas: Resource: type: object properties: data: type: object properties: items: type: array #...more message: #...more status: #...more paths: #...more responses: \u0026#39;200\u0026#39;: description: OK content: application/json: schema: $ref: \u0026#39;#/components/schemas/Resource\u0026#39; 但這樣一來就變得很不彈性，在幾乎沒什麼 $ref 會引用到相同內容的情況下，還不如直接 inline，而且要改的地方有點太多了(懶)\n2. 先把檔案修正成可以通過 OpenAPI 的 linter 檢查，然後再用工具 取代掉 $ref 的部分 想說反正只是為了能夠使用代碼生成工具，不想花太多精力大改原本的 OpenAPI 文件，於是最後採取了這個方法。\n剛剛有稍微提到原本的格式跑 lint 時會有錯誤，需要進行修正，只要能夠成功跑過 linter 的檢查，就可以再用工具把 $ref 引用的地方全都取代成相對應的定義內容。這篇問答有提供兩種工具都能達成這個目的，在這邊我們選用了 redockly-cli（沒有為什麼只是我們也有用 redoc）。\nrun linter 首先修正上面剛剛提到的 properties 和 $ref 的部分後，就可以成功跑過 linter：\n1 $ redocly lint openapi.yaml warning 的部分不用理他。\nbundle file and dereferenced 然後再對檔案跑 bundle 指令：\n1 $ redocly bundle --dereferenced openapi.yaml --output openapi_0317.yaml 然後再一次跑 oapi-codegen 指令：\n1 $ oapi-codegen -package ports openapi_0317.yaml \u0026gt; openapi.gen.go 總算成功 gen 出檔案啦🎉\nNote 在預設不帶任何 -generate 參數的情況下，該指令會幫我們產生所有包含 server, types, client, spec 等等相關程式碼在指定輸出的檔案裡，且預設使用的 server 是 Echo。（詳細說明參考文件）\n假設我們的需求是使用 gin ，並且只需要 server 和 types 部分的程式碼\nserver：生成 server 接口以及相關的程式碼，包括將參數綁定到 struct、參數類型錯誤 throw Exception 的處理等等 types：定義在 OpenAPI components 當中的類型(struct)，包含 request params/body 和 response body\n並且分別放置於不同檔案中，可以這樣做：\n先產生 gin server 的檔案\n1 $ oapi-codegen -package ports -generate gin openapi_0317.yaml \u0026gt; openapi_api.gen.go 再產生 types 的檔案\n1 $ oapi-codegen -package ports -generate types openapi_0317.yaml \u0026gt; openapi_types.gen.go ","date":"Mar 17","permalink":"//localhost:1313/posts/resolve-oapi-codegen-error/","tags":["Golang","OpenAPI"],"title":"解決使用 oapi-codegen 時報錯 unexpected reference depth"},{"categories":null,"contents":" 前言 自從從 Medium 換過來自架部落格後，SEO 的事情也都得自己處理。但雖然說是「處理」，也只是做一些基本的設定而已，例如裝個 Search Console、提交 sitemap（但其實使用的靜態網站生產器 Hexo 就已經有做到自動生產、更新 sitemap）。唯一的手動作業就是每次發表新文章後，為了加快 Google 索引到新文章頁面的速度，我都還是會進到 Search Console 後台，手動輸入頁面網址要求建立索引（網址審查\u0026gt;測試線上網址\u0026gt;建立索引)。\n身為一個能夠自動就不手動的懶人，突然想到之前曾在公司專案中使用過 Google Indexing API 提交要加入索引的網址，那我應該也可以來幫我的部落格串看看吧？\n在尋找方法的過程中，雖然原本就是使用 Netlify 架站，但一年前的記憶有點模糊(可能也是複製貼上的關係)，裡面很多功能其實也沒碰過，中途不少次因為遇到某種限制而又改變原本的做/解法，覺得這個過程也是學習到了不少，或是有機會為其他人避坑(?)，因此有了這篇文章。\n實作 初步規劃 這個功能的流程其實非常簡單，就是——發表文章後（deploy 成功）馬上觸發打 Google Indexing API 的程式。\n首先需要思考的問題是，要如何接收 deploy 完成的訊息？ 以及 「打 Google Indexing API 的程式」要在哪裡執行？\n第一個想法是：看看 Netlify 在 deploy 成功後，有沒有什麼事件可以監聽。\n於是搜尋到了官方文件關於 Deploy notifications 的說明，有支援多種接收通知的方式，Slack、email、webhook 等等。看起來比較適合的方式可能是透過 webhook，另外起一個 http server 並註冊一個 endpoint，server 一接收到 request 就立刻打 Google Indexing API。 但這麼一來，就還得另外 run 一個 http server，為了完成這個小任務還得再額外開一個服務，總覺得哪裏怪怪的。所以後來又找了一下有沒有其他更適合的做法，結果就看到了 Netlify Functions。\n什麼是 Netlify Functions Netlify Functions 是 Netlify 提供的一個類似 aws lamda 的功能(實際上也是基於 aws lamda 去實現的)，可以輕易地部署 serverless 的服務。\n然而 functions 都是基於專案(也就是透過 Netlify 所構建的網站)，一個專案底下可以有多個 functions，這些 functions 需要被放在特定資料夾下面才會一同跟著專案被部署。（預設的資料夾位置在 YOUR_BASE_DIRECTORY/netlify/functions/，可以自行透過設定更改)\n而這些部署在線上的 functions，都可以藉由特定的路由去觸發執行。 例如，一個用 JavaScript 寫的 functions 檔案名為 hello.js，被放在 netlify/functions/ 底下，完整路徑是：\nYOUR_BASE_DIRECTORY/netlify/functions/hello.js 對應的路由就是：\nBASE_URL_OF_YOUR_SITE/.netlify/functions/hello 只要戳這個 endpoint，隨便一種 Http Method 都可以，就能觸發這個 function。\n📝 Note: 目前 functions 支援的程式語言只有 Typescript、JavaScript 以及 Golang 。\n但接著又想到一件事，既然 functions 都是在專案底下，那他是否能透過某種方式監聽到專案的部署成功事件，只要專案一部署成功，就自動 call 這個 function，也不需要設定 webhook url 了？答案是可以的，Netlify 提供了一系列的 triggers，只要將 functions 按照事件名稱命名，就會在該事件發生時，直接執行同名 function。事件當中當然也包括部署成功事件 deploy-succeeded ，所以只要將 function 命名為 deploy-succeeded，function 就會在專案部署完成時被執行。\n使用 Netlify Functions 總算進入到實作的環節啦!在這邊會使用 Golang 進行實作。 首先，在專案底下新建檔案 netlify/functions/deploy-succeeded/deploy-succeeded.go\n📝 Note: 由於使用 Golang，一個 function 會視作為一個 Go module，裡面包含一個有 main function 的檔案，所以需要用資料夾來分層。但如果使用 JS 就不需要資料夾分層，一個檔案就是一個 function。\n以下是官方文件提供的 function 範本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // ./netlify/functions/deploy-succeeded/deploy-succeeded.go package main import ( \u0026#34;github.com/aws/aws-lambda-go/events\u0026#34; \u0026#34;github.com/aws/aws-lambda-go/lambda\u0026#34; ) func handler(request events.APIGatewayProxyRequest) (*events.APIGatewayProxyResponse, error) { // 這邊是 function 的邏輯 } func main() { // 這塊不需要動 lambda.Start(handler) } 想要先測試看看，是否這個 function 真的會在每次部署完成後被觸發執行，也順便看看收到的 request payload 會是什麼，所以在 handler 方法裡面加上：\n1 2 3 4 func handler(request events.APIGatewayProxyRequest) (*events.APIGatewayProxyResponse, error) { // 試著把 request.Body 印出來 fmt.Println(request.Body) } 結果發現真的有被執行，我們可以到 Netlify 後台去看 function 的 log。進入 https://app.netlify.com/sites/{your_site}/functions ，點選剛剛 deploy 的 function： 就可以進到該 function 的頁面瀏覽 log： log 印出來的內容大概長這樣，但因爲資料有點太多，這邊就沒貼完整內容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 // 敏感資訊有用*號遮罩 { \u0026#34;payload\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;63f9e14********6916d\u0026#34;, \u0026#34;site_id\u0026#34;: \u0026#34;********-6b6d-4df7-a413-********\u0026#34;, \u0026#34;build_id\u0026#34;: \u0026#34;63f9e144bb8728000846916b\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;ready\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;emmielin\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://emmie.work\u0026#34;, \u0026#34;ssl_url\u0026#34;: \u0026#34;https://emmie.work\u0026#34;, \u0026#34;admin_url\u0026#34;: \u0026#34;https://app.netlify.com/sites/emmielin\u0026#34;, \u0026#34;deploy_url\u0026#34;: \u0026#34;http://main--emmielin.netlify.app\u0026#34;, \u0026#34;deploy_ssl_url\u0026#34;: \u0026#34;https://main--emmielin.netlify.app\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2023-02-25T10:21:56.064Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-02-25T10:22:11.735Z\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;************************\u0026#34;, \u0026#34;error_message\u0026#34;: null, \u0026#34;required\u0026#34;: [], \u0026#34;required_functions\u0026#34;: [], \u0026#34;commit_ref\u0026#34;: \u0026#34;f3fb856c951b6979f22********90\u0026#34;, \u0026#34;review_id\u0026#34;: null, \u0026#34;branch\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;commit_url\u0026#34;: \u0026#34;https://github.com/linxinemily/hugo-emmie-blog/commit/f3fb856c951b6979f22ffad191843dc831164690\u0026#34;, \u0026#34;skipped\u0026#34;: null, \u0026#34;locked\u0026#34;: null, \u0026#34;log_access_attributes\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;firebase\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://netlify-builds9.firebaseio.com/builds/63f9e144bb8728000846916b/log\u0026#34;, \u0026#34;database\u0026#34;: \u0026#34;netlify-builds9\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;https://netlify-builds9.firebaseio.com\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/builds/63f9e144bb8728000846916b/log\u0026#34;, \u0026#34;token\u0026#34;: \u0026#34;************************\u0026#34;, }, \u0026#34;title\u0026#34;: \u0026#34;commit msg\u0026#34;, // more info... }, \u0026#34;site\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;********-6b6d-4df7-a413-********\u0026#34;, \u0026#34;site_id\u0026#34;: \u0026#34;********-6b6d-4df7-a413-********\u0026#34;, \u0026#34;plan\u0026#34;: \u0026#34;nf_team_dev\u0026#34;, \u0026#34;ssl_plan\u0026#34;: null, \u0026#34;premium\u0026#34;: false, \u0026#34;claimed\u0026#34;: true, \u0026#34;name\u0026#34;: \u0026#34;emmielin\u0026#34;, \u0026#34;custom_domain\u0026#34;: \u0026#34;emmie.work\u0026#34;, \u0026#34;domain_suffix_branch\u0026#34;: null, \u0026#34;domain_suffix_deploy_preview\u0026#34;: null, \u0026#34;domain_aliases\u0026#34;: [], \u0026#34;password\u0026#34;: null, \u0026#34;password_hash\u0026#34;: null, \u0026#34;sso_login\u0026#34;: false, \u0026#34;sso_login_context\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;notification_email\u0026#34;: null, \u0026#34;url\u0026#34;: \u0026#34;https://emmie.work\u0026#34;, \u0026#34;admin_url\u0026#34;: \u0026#34;https://app.netlify.com/sites/emmielin\u0026#34;, \u0026#34;deploy_id\u0026#34;: \u0026#34;63f9e14********6916d\u0026#34;, \u0026#34;build_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;deploy_url\u0026#34;: \u0026#34;http://main--emmielin.netlify.app\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;current\u0026#34;, \u0026#34;screenshot_url\u0026#34;: null, \u0026#34;created_at\u0026#34;: \u0026#34;2022-07-18T16:18:18.628Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-02-25T10:22:11.738Z\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;************************\u0026#34;, \u0026#34;error_message\u0026#34;: null, \u0026#34;ssl\u0026#34;: true, \u0026#34;ssl_url\u0026#34;: \u0026#34;https://emmie.work\u0026#34;, \u0026#34;force_ssl\u0026#34;: true, \u0026#34;ssl_status\u0026#34;: null, \u0026#34;max_domain_aliases\u0026#34;: 100, // more info... } } 如果要在 local 開發 function 的話，可以安裝 Netlify CLI，在專案底下跑：\n$ netlify functions:serve 成功跑起來的話預設會在 9999 port： 然後就可以用 Postman 打 function 的 endpoint： 如何取得新文章 URL 確定 Netlify Functions 可以達成我們的需求後，在串接 Indexing API 前，總得知道該怎麼把新文章的網址推送給 Indexing API 吧！\n原本的想法是，由於 Hugo 每次 build 的時候都會自動幫我們更新 sitemap 檔案，因此或許可以透過新舊 sitemap 的比對檢查是否有新增的 page url，如果有的話就把這些 url 推送給 Google Indexing API。但問題就來了，要有舊檔案可以拿出來比較，那就得在每次執行這個 function 完存下當前的 sitemap 檔案，這樣才能在下一次執行 function 時，取得上次存下的 sitemap 檔案與新的做比對。然而，在 functions 當中無法對專案進行檔案的讀寫，(有人發問被官方回覆在此)，這麼一來還得另外找一個外部空間例如 AWS S3 之類的去存放這個檔案，覺得有點太麻煩了，而且這個功能應該也不需要做到這麼自動化(畢竟暫時只有我要用)。\n所以後來發現 payload 當中有一個欄位 payload.title 是每次 commit 的訊息，因爲 Netlify 的設定是一 push commit 就會觸發 deploy，所以每次 deploy 一定都會有一個 commit msg。於是想到可以直接利用 commit msg 帶入新文章的 slug，在 payload 中取得 payload.title 解析出 slug 字串後組出新文章的網址。雖然好像有點土法煉鋼，不過感覺還挺可行的。\n串接 Google Indexing API 確定資料的取得都沒問題後，接下來就是進入串接 Indexing API 的部分了。完成官方文件事前準備的步驟「為用戶端建立專案」、「建立服務帳戶」、「將服務帳戶新增為網站擁有者」之後，就可以根據要使用的程式語言安裝 google api sdk 程式，這邊選擇使用 Golang 的 sdk。\n剛剛第二個步驟「建立服務帳戶」時，下載了一個金鑰檔案(按照建議檔案類型選擇JSON)存在本地電腦裡，使用這個金鑰的方式很簡單，本地端開發的話，只要在命令列宣告個環境變數：Ref\n$ export GOOGLE_APPLICATION_CREDENTIALS=\u0026#34;KEY_PATH\u0026#34; //KEY_PATH 取代為剛剛下載的金鑰檔案路徑 先測試一下串接有沒有成功，帶個測試網址發送看看：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // ./netlify/functions/deploy-succeeded/deploy-succeeded.go package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github.com/aws/aws-lambda-go/events\u0026#34; \u0026#34;github.com/aws/aws-lambda-go/lambda\u0026#34; \u0026#34;google.golang.org/api/indexing/v3\u0026#34; ) func handler(request events.APIGatewayProxyRequest) (*events.APIGatewayProxyResponse, error) { ctx := context.Background() indexingService, err := indexing.NewService(ctx) if err != nil { log.Fatalln(err) } fullUrl := \u0026#34;https://emmie.work/posts/test\u0026#34; //先寫死一個測試網址 notification := \u0026amp;indexing.UrlNotification{ Url: fullUrl, Type: \u0026#34;URL_UPDATED\u0026#34;, } res, err := indexingService.UrlNotifications.Publish(notification).Do() if err != nil { log.Fatalln(err) } log.Println(res.ServerResponse) return \u0026amp;events.APIGatewayProxyResponse{ StatusCode: 200, Body: fmt.Sprintf(\u0026#34;Success send request to notify Google of new article, url: %s\u0026#34;, fullUrl), }, nil } func main() { lambda.Start(handler) } 在同個命令列 session 下剛剛的 netlify functions:serve 指令，看起來是 work 的。 OK，問題又來了，當這段程式要放在 Netlify 上面跑時，難不成要把這個金鑰檔案也連同上傳到 github repo 嗎，聽起來有點不太安全，而且還記得剛剛提到 function 裡面無法存取專案當中的檔案，所以這條路也不可行。那該怎辦呢？後來看到有網友也有類似問題（但我突然找不到原發問連結），總之最後採用的方法是將環境變數的值改成金鑰 JSON 檔內容，然後在程式裡面取得環境變數的值後，透過 option 設定金鑰的值：\n$ export GOOGLE_APPLICATION_CREDENTIALS=\u0026#39;{ \u0026#34;type\u0026#34;: \u0026#34;service_account\u0026#34;, \u0026#34;project_id\u0026#34;: \u0026#34;emmie-hugo-blog\u0026#34;, \u0026#34;private_key_id\u0026#34;:\u0026#34;xxxxxx\u0026#34;, //... }\u0026#39; 1 2 3 4 5 6 func handler(request events.APIGatewayProxyRequest) (*events.APIGatewayProxyResponse, error) { //... credentialJsonStr := os.Getenv(\u0026#34;GOOGLE_APPLICATION_CREDENTIALS\u0026#34;) indexingService, err := indexing.NewService(ctx, option.WithCredentialsJSON([]byte(credentialJsonStr))) //... } 這樣一來，就能夠單純透過設定環境變數的值取代需要存取檔案的方式。但要在部署時加上這個變數，我們還得再做兩個動作，一是在 ./netlify.toml 檔案，設定環境變數的 KEY：\n1 2 3 4 # ./netlify.toml [context.production.environment] HUGO_ENV = \u0026#34;production\u0026#34; GOOGLE_APPLICATION_CREDENTIALS = \u0026#34;$GOOGLE_APPLICATION_CREDENTIALS\u0026#34; 二是到 Netlify 後台設定環境變數的值： 然後就大功告成了！！\n這邊直接附上最後完成的 code： https://github.com/linxinemily/google-indexing-netlify-function/blob/main/deploy-succeeded.go\n再來測試看看發一個 commit 然後 push:\ngit commit -m \u0026#34;new article: netlify-function-google-indexing-api\u0026#34; \u0026amp;\u0026amp; git push 驗證一下是否有成功提交索引，到後台看 function 有沒有 log，有顯示代表成功： 後記 以上，大概就完成了 90% 的人工作業（剩下 10％ 是要自己打 commit msg 的部分），不過也已經心滿意足了！比較大的收穫就是發掘了 Netlify Functions 這個不錯用的功能，以及重溫一下串 Google API 的回憶。 現在能想到唯一的缺陷是，當一次推多個 commit 時，由於 deploy 的 payload 只會有最新一個 commit 的相關資訊，所以如果這幾個 commit 都包含有一篇新文章，那就只有最後發的那個 commit 的文章會被提交索引，不過我寫文頻率沒有高成那樣所以應該是不太可能會遇到這種情況，所以就先略過了。剩下的部分就看未來有沒有遇到什麼使用上的困難再來優化吧！\n","date":"Feb 27","permalink":"//localhost:1313/posts/netlify-function-google-indexing-api/","tags":["Golang","Third-Party Integration"],"title":"讓架在 Netlify 上的網站發文同時向 Google 要求為新頁面建立索引! - 使用 Netlify Functions 串接 Google Indexing API"},{"categories":null,"contents":"前幾天閱讀到這篇官方 wiki ，其中的 Using reference to loop iterator variable，也就是關於在迴圈當中引用迭代變數常犯的錯誤。當中有個範例一開始讓我不是很理解，後來終於搞懂，所以才想說筆記下來，也順便釐清一下思路。\n首先，第一個範例滿好理解的：\n1 2 3 4 5 6 7 8 func main() { var out []*int for i := 0; i \u0026lt; 3; i++ { out = append(out, \u0026amp;i) } fmt.Println(\u0026#34;Values:\u0026#34;, *out[0], *out[1], *out[2]) fmt.Println(\u0026#34;Addresses:\u0026#34;, out[0], out[1], out[2]) } 輸出的結果會是：\nValues: 3 3 3 Addresses: 0x40e020 0x40e020 0x40e020 原因是，由於 append 到 out 這個 slice 的參數是 \u0026amp;i ，傳入的是一個 int 類型的變數指標（ out 的型別也是一個 存放多個 int 類型的變數指標 的 slice），所以每個迭代都是把同一個變數指標 append 到 out 裡面，因此當迭代到最後一次時，該變數指標裡面存放的值已經變成 3 ，所以印出來就是都是 3 。\n而解決的辦法就是把 i 的值複製到另一個新變數上：\n1 2 3 4 for i := 0; i \u0026lt; 3; i++ { i := i // Copy i into a new variable. out = append(out, \u0026amp;i) } 這樣一來， 就能保證每次迭代當中的 \u0026amp;i 就是當前迭代所創造的新變數的指標，不會導致非預期的結果，也讓原本只能存活在 for scope 當中的變數 i 能夠在迴圈之外被引用，不會在迴圈結束後就被回收。\n接下來的另一個範例，就是讓我一開始不是很能理解的地方：\n1 2 3 4 5 6 7 func main() { var out [][]int for _, i := range [][1]int{{1}, {2}, {3}} { out = append(out, i[:]) } fmt.Println(\u0026#34;Values:\u0026#34;, out) } 以上程式的輸出是：\nValues: [[3] [3] [3]] 但如果當只改動一個地方：\n1 2 3 4 5 6 7 func main() { var out [][]int for _, i := range [][]int{{1}, {2}, {3}} { // 把長度 1 拿掉 out = append(out, i[:]) } fmt.Println(\u0026#34;Values:\u0026#34;, out) } 以上的輸出就變成預期的結果：\nValues: [[1] [2] [3]] ..等等，不是才差一個字嗎？實際搞懂後，差一個字但其實差很多，因為這兩個範例當中的迭代變數類型完全不同。\n原本的範例當中，被迭代的 slice 裏面放的是 長度為 1 且內容物為 int 類型 的陣列： [][1]int{{1}, {2}, {3}} ，而後面更動的版本，被迭代的 slice 裡面放的是另一個 slice： [][]int{{1}, {2}, {3}} 。因為在 Golang 當中，宣告陣列和 slice 的寫法很像，差別在於陣列是需要指定長度的，不指定長度的話會變成 slice。\n1 2 var a [1]int // 帶指定長度會是陣列 var b []int // 不帶長度會是 slice 而且陣列和其他純值類型一樣是屬於 value type。也就是當把陣列賦值給另一個變數時，等同拷貝一份一樣的陣列進去新的變數，原始陣列不會受到該新陣列的更動影響：\n1 2 3 4 5 arr := [1]int{1} arr2 := arr arr2[0] = 2 fmt.Println(arr) // output: [1] 因此，在兩個範例當中 i[:] 所代表的意義就不同。第一個範例中的 i 是陣列，i[:] 代表一個引用 i 這個陣列的 slice （slice 底層指向的陣列指標 = \u0026amp;i），雖然每個迭代中都會創造一個新的 slice，但這些 slice 底層所引用的都是同一個變數指標 。\n到這邊就可以看出，其實這個狀況跟最一開始 i 為 int 類型變數的範例一樣， 由於每次迭代時， i 的值都一直在替換，直到迴圈結束， i 的值停留在最後一次迭代當中被賦予的值。\n而第二個範例中， i[:] 是代表將原先 i 這個 slice 複製出一份 slice，而基於複製 slice 的原理，這兩個 slice 底層都會指向同一個陣列（複製的是 slice 的 header，包含陣列的(第一個元素的)指標、長度的值）\nWhat exactly is this slice variable? It’s not quite the full story, but for now think of a slice as a little data structure with two elements: a length and a pointer to an element of an array. You can think of it as being built like this behind the scenes:\ntype sliceHeader struct { Length int ZerothElement *byte } 但 slice 本身仍是一個 value\nIt’s important to understand that even though a slice contains a pointer, it is itself a value. Under the covers, it is a struct value holding a pointer and a length. It is not a pointer to a struct.\n所以當下一次迭代時， i 的內容換成下一個 slice，會再次複製 i 的值，也就是 header 的部分給新的 slice，每次迭代中產生的新 slice 都和迭代當下的 slice 有相同的 header，每個複製也都引用和複製對象相同的底層陣列。整個流程始終沒有去引用到 i 的指標，也就不會有上面範例的問題。\n總結，迭代變數在迭代同時，值也會不斷改變，如果在迴圈中有引用到迭代變數，可能會有非預期的行為。\nReferences CommonMistakes\nresearch!rsc: Go Data Structures\nArrays, slices (and strings): The mechanics of \u0026lsquo;append\u0026rsquo; - The Go Programming Language\n","date":"Feb 21","permalink":"//localhost:1313/posts/golang-using-reference-to-loop-iterator-variable/","tags":["Golang"],"title":"Golang 常見錯誤 - 在迴圈當中引用迭代變數(iterator variable)"},{"categories":null,"contents":" 前情提要 前陣子將公司一個 Laravel 專案當中通知的功能部分切出到另一個用 Golang 構建的服務，並且把資料從 MariaDB 遷移到 AWS DynamoDB。想說稍微紀錄一下這個過程，算是一個收穫滿多的經驗。\n由於原本存在 MariaDB 的通知資料量日益肥大，雖然當前仍不算是巨量資料，大約千萬級資料量而已，但是光是這個等級的資料量，只要不小心下一個範圍性的 select 語句都有可能會造成整個 DB 卡死然後服務掛掉（真實發生過在 production 環境上的事件…）。然而通知在我們的系統當中其實僅是一個輔助的功能，但一有問題卻可能直接導致整個服務停擺，怎麼想都不太合理。因此，「隔離」就是我們首要的目的——通知的資料不該和主服務的資料擺在同個資料庫裡 。\n📝 Note: 當資料量到達百萬級以上後，count(*) 語法明顯速度變很慢，像這樣的查詢語句 select count(*) from UserNotification where id \u0026gt; 51306320 and id \u0026lt;= 57615005 order by id 執行起來就要兩秒多。\n既然要把資料搬出去，要搬到哪裡就是就是第二個問題，而我們後來會選用 AWS DynamoDB 的原因包括：\n面對乘載資料量的變化，DB 可以自動隨之擴展和縮減 查詢有既定的模式和規則，不太會有變動（如：取得通知未讀數量、將通知已讀 etc.），也不需要複雜的 join 或 sub queries 等等 不需要嚴格的的資料一致性，只要有最終一致即可（DynamoDB Consistency Model 的預設值，也是能保持最佳效能的推薦選項） 原本就有在使用 AWS 的服務，之後若有需要和 AWS 其他服務整合時也比較方便 而之所以會另建一個服務，主要是為了將隔離性提高到應用層的部分，以便之後將其他通知相關的功能都切出去（ex: 推播），選擇 Golang 則是因為其簡單快速的特性，也很適合拿來搭建微服務（還有一部分私心是想實際將 Golang 運用在公司專案上）。 此外，使用 Golang 還有一個好處就是能夠使用迸發程式對 DynamoDB 進行操作。DynamoDB 本身就有能力消化同時數千個以上寫入/讀取的請求（每秒的請求吞吐量上限取決於所選擇的計價方式/ Read/write capacity mode），非常適合搭配支援 concurrency 的程式語言使用，在需要的時候可以透過迸發程式大幅提高處理大量資料的效率。\nMigrate 之前的準備 在 migrate 資料之前，我們所進行的服務替換是這樣的：\n原本所有 notification 相關 API 都不動，分別新增每一隻 API 對應的 API 加上 v2 前綴。而 v2 所做的事情都和 v1 相同，只是原本操作資料時是對 MariaDB 操作，都改成對外部通知服務操作。\n而在新增通知資料的部分，由於通知是在使用者進行某些特定行為時才會被建立，所以這個部分的改動是在每個操作行為之後原本會觸發新增通知的地方，全部也都加上觸發新增 v2 的通知。\n除此之外，新增通知與推播通知是獨立運作的：\n使用者進行某些特定行為，觸發新增通知事件： 當下立即新增通知資料，同時派發一個推播通知的 queue job（新增資料的 id 會傳給 queue job） Queue worker 消化 job 推播通知： 透過傳進來的 id 找到欲推播的資料，再進行推播 在這個版本當中，新舊的 Notification API 會並存（API 主要就是提供讀取通知列表、更新通知已讀狀態），且同時儲存新舊版通知資料，但在推播的 job 當中是到新 DB 找資料。\nMigrate 時遇到的問題與解法 我們打算要 migrate 最近三個月的資料，先前已經有準備好一隻將 MariaDB 資料 migrate 到 DynamoDB 的程式。照原本計劃在上版前要先跑 migrate，總共有 600 多萬筆資料，估計至少要一個小時以上才跑得完，但舊資料有可能會在這段期間內被更新（已讀狀態），導致新舊資料不同步的問題：\nmigrate 過程中，舊資料可能會被更新，新資料卻沒有被更新，導致資料不同步。\n解決這個問題的方法其實顯而易見，就是 在更新舊 DB 資料的同時，也連同更新在新 DB 的同一筆資料。 同樣地，為了相容性（前端 web/APP 也要更換成打 v2 API 的版本，但 web 會先更新、APP 尚未準備好），更新新 DB 資料時也要連同更新在舊 DB 的同一筆資料，這樣就算前端換成打 v2 後 APP 仍在打 v1，兩邊的資料也都會是同步的。如此一來， migrate 也就不需要在上版前做，而是在上版之後還能夠很有餘裕地慢慢跑。\n於是加上修改也同步之後，接下來的流程大概是這樣：\n後端上版（新增修改皆同步資料的版本） 跑 migrate 指令 migrate 完成後，前端/APP 再上版 （改成打 v2 API 的版本） 其實更無縫的方法是直接把 v1 API 背後都改成串接新服務，並提供相同的回傳資料格式，如此的話前端也無需替換接口。但由於在「讀取列表」API 的分頁參數有做改動（原本 v1 是使用頁數去取不同分頁的資料，但在 DynamoDB 取資料時無法用指定頁數的方式，不支持像是 SQL 的 offset 語法的用法或可以達到類似效果的方法，而是要指定從哪筆資料開始往下取幾筆的方式，類似 Cursor 的概念），前端必定得進行相對應的修改，無法直接抽換。\n不過透過以上的做法，已經能夠在不讓使用者覺察的前提下，將資料庫進行抽換並完成資料的搬移。後續就只需要持續追蹤 Log，如果 v1 API 都沒有再被呼叫的話，就可以直接把 v1 都拔掉，也無需再同步將資料寫入舊 DB、更新舊 DB 的資料 。\n","date":"Feb 08","permalink":"//localhost:1313/posts/migrate-data-from-mariadb-to-dynamodb/","tags":["DynamoDB"],"title":"將資料從 MariaDB 遷移至 AWS DynamoDB 過程紀錄"},{"categories":null,"contents":"在 Laravel 當中，我們可以透過「動態關聯屬性(Dynamic relationship properties)」直接取得 Model 的關聯資料，而該行為被官方稱為 「Lazy Loading」，當取值時就會自動將關聯資料載入，非常方便。但使用上一不小心就很有可能會造成 N+1 問題。\nN+1 問題通常是指，在得到一個 Models of Collection/Array 後，又在遍歷每個 Model 時，透過 Lazy Loading 取得其關聯資料，會導致 有 N 個 Model 就會執行 N+1 次 Query。過多的 DB Query 次數可能會對效能造成嚴重影響。\nLaravel 8 開始就有提供避免 Lazy Loading 的方法， 只要在 App\\Providers\\AppServiceProvider 當中的 boot() 方法裡面加上：\n1 2 3 4 5 6 7 // app/Providers/AppServiceProvider.php use Illuminate\\Database\\Eloquent\\Model; public function boot() { Model::preventLazyLoading(! app()-\u0026gt;isProduction()); //預設為 true } 如此一來，當 Lazy Loading 被觸發時，就會直接拋出例外 (Illuminate\\Database\\LazyLoadingViolationException)\n而當初該新功能發布時，laravel-news 網站有一篇文章就在介紹這個功能。該篇文章當中舉的例子為，有兩個 Model - User 和 Posts 為一對多關係：\n1 2 3 $user = User::first(); $user-\u0026gt;posts; // 這邊就會觸發 Lazy Loading, 將所有 user 的 post 都從 DB 撈出 所以如果加上 Model::preventLazyLoading() ，執行上面範例時應該就會拋出 Illuminate\\Database\\LazyLoadingViolationException 阻止我們透過 Lazy Loading 得到 posts。\n於是打開專案來試試，卻發現一切正常，沒有例外拋出\u0026hellip;\n但如果換一個方法試試：\n這時候才會如預期拋出例外。\n另外，如果當 DB 裡只有一筆 user 資料，就算像上面這樣取 all()，也不會拋出例外。\n一開始很疑惑為什麼範例的 code 執行後沒有拋出例外，所以就研究了一下原始碼的部分，順便看一下這個功能是如何實現的。\n原始碼分析 首先，從 Illuminate\\Database\\Eloquent\\Model::preventLazyLoading() 這個方法開始看起：\n1 2 3 4 public static function preventLazyLoading($value = true) { static::$modelsShouldPreventLazyLoading = $value; } 這邊會將 Illuminate\\Database\\Eloquent\\Model 當中的一個靜態屬性 $modelsShouldPreventLazyLoading 設值成傳入的布林值。\n該屬性預設為 false：\n1 protected static $modelsShouldPreventLazyLoading = false; 但其實 Illuminate\\Database\\Eloquent\\Model 另外還有一個非靜態屬性 $preventsLazyLoading（待會會提到在哪裡被使用）\n1 public $preventsLazyLoading = false; 當執行 DB Query，取得 App\\Models\\User 時(eg: User::first();)，會進入以下方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //src/Illuminate/Database/Eloquent/Builder.php public function hydrate(array $items) { $instance = $this-\u0026gt;newModelInstance(); return $instance-\u0026gt;newCollection(array_map(function ($item) use ($items, $instance) { $model = $instance-\u0026gt;newFromBuilder($item); if (count($items) \u0026gt; 1) { $model-\u0026gt;preventsLazyLoading = Model::preventsLazyLoading(); } return $model; }, $items)); } 如果執行 User::first()，此處的 $items 引數會是一個陣列，內含一個 stdClass 物件 (從 users table 取出的第一個 row 的資料)，像這樣：\n1 2 3 4 5 6 7 8 9 10 11 12 array:1 [ 0 =\u0026gt; {#4352 +\u0026#34;id\u0026#34;: 1 +\u0026#34;name\u0026#34;: \u0026#34;Mrs. Gisselle Sauer\u0026#34; +\u0026#34;email\u0026#34;: \u0026#34;dion.kiehn@example.com\u0026#34; +\u0026#34;email_verified_at\u0026#34;: \u0026#34;2022-12-22 03:53:59\u0026#34; +\u0026#34;password\u0026#34;: \u0026#34;$2y$10$92IXUNpkjO0rOQ5byMi.Ye4oKoEa3Ro9llC/.og/at2.uheWG/igi\u0026#34; +\u0026#34;remember_token\u0026#34;: \u0026#34;jq4qLUs2qQ\u0026#34; +\u0026#34;created_at\u0026#34;: \u0026#34;2022-12-22 03:53:59\u0026#34; +\u0026#34;updated_at\u0026#34;: \u0026#34;2022-12-22 03:53:59\u0026#34; } ] 接著在遍歷陣列的過程中，將遍歷到的 stdClass 物件轉成 Eloquent Model 時，會先判斷如果 $items 陣列長度大於 1，才會將這個 Model(在此範例也就是 App\\Models\\User)的 $preventsLazyLoading 屬性設為Model::preventsLazyLoading() 的值，而這個靜態方法其實回傳的就是先前我們在 App\\Providers\\AppServiceProvider 設定的靜態屬性 $modelsShouldPreventLazyLoading：\n1 2 3 4 public static function preventsLazyLoading() { return static::$modelsShouldPreventLazyLoading; } 接著，當呼叫 $user-\u0026gt;posts 時，會進入 Illuminate\\Database\\Eloquent\\Concerns\\HasAttributes 當中的 getRelationValue() 方法:\n1 2 3 4 5 6 7 8 9 10 11 // src/Illuminate/Database/Eloquent/Concerns/HasAttributes.php public function getRelationValue($key) { ... if ($this-\u0026gt;preventsLazyLoading) { // here $this-\u0026gt;handleLazyLoadingViolation($key); } return $this-\u0026gt;getRelationshipFromMethod($key); } 當 $preventsLazyLoading 為 true 時，就會拋出例外\n1 2 3 4 5 6 7 // src/Illuminate/Database/Eloquent/Concerns/HasAttributes.php protected function handleLazyLoadingViolation($key) { ... throw new LazyLoadingViolationException($this, $key); } 也就是說，從 DB 取出的資料筆數需大於 1 ，對該 Model 取關聯時才會觸發 Prevent Lazy Loading 的效果。\n所以如果撈出的結果都是一筆資料，就也不會觸發 Prevent Lazy Loading 了。\n1 2 3 4 5 $user = User::first(); // 只有從 DB 撈出一筆資料 $user-\u0026gt;posts; // no exception $users = User::all(); // 假使 DB 裏其實也只有一筆 user 資料 $users[0]-\u0026gt;posts; // no exception 其實按照常理，大概能夠理解爲什麼會有這種效果，因為只有一個 Model 的時候，取得其底下關聯，應該不能算是 N+1 問題。（不過該網站的例子為什麼這樣舉就不得而知，算是小踩坑了下）\n","date":"Dec 29","permalink":"//localhost:1313/posts/laravel-prevent-lazy-loading/","tags":["Laravel"],"title":"Laravel Prevent Lazy Loading 踩坑心得及原理分析"},{"categories":null,"contents":"前幾天遇到一個狀況，原本程式裡有一段邏輯是 「如果該筆資料不存在，就寫入新資料，但如果已存在，就直接回傳該筆已存在的資料」，程式碼大概長這樣：\n1 2 3 4 5 6 7 8 9 $snapshot = OrderSnapshot::where(\u0026#39;order_id\u0026#39;, $order-\u0026gt;id)-\u0026gt;first(); if (!empty($snapshot)) { return $snapshot; } // do something... return OrderSnapshot::create([\u0026#39;payload\u0026#39; =\u0026gt; $order_array]); 上面程式碼其實也可以使用 Laravel 的 firstOrCreate 方法做簡化:\n1 2 3 4 return OrderSnapshot::firstOrCreate( [\u0026#39;order_id\u0026#39; =\u0026gt; $order-\u0026gt;id], [\u0026#39;payload\u0026#39; =\u0026gt; $order_array] ) 這段邏輯看起來很簡單，在單一 process 的情況下，這段程式碼確實沒有任何問題，但如果今天同時有兩個 process 要執行這段程式的話，就可能會有非預期的結果出現。 由於不論是上面的程式碼，或是簡化後的程式碼，如果沒有撈出資料的話（也就是資料不存在），都是要繼續往下執行新增資料的動作，而「撈出資料」和「新增資料」都是單獨的 Query，所以如果幾乎同時執行這段程式時，可能就會產生兩筆相同的資料：\n而要解決這個問題，大概有以下幾種辦法：\n1. 避免多個 process 執行 如果是因為放在 job 裡面，同時有多個 queue worker 在消化這些 job，就保持 queue worker 的數量為 1。 但我們這次遇到的情況並不適用，因為還可以透過 API Request realtime 執行這段程式。而且如果遇到真的很耗時的工作，也不可能為此只開一個 worker。\n2. 使用 INSERT INTO .. ON DUPLICATE KEY 語法 也就是說將兩個 Query 合併成一個 Query，讓資料庫去判斷資料存不存在，不存在就新增，存在則改成更新。 但這又不太符合我們的情境，因為如果已存在，並不需要對該筆資料做更新，直接取出即可。\n3. 利用外部服務實現分布式鎖機制 由於 PHP 單執行緒的特性，本身沒有這種機制，所以只能藉由外部的服務來實現分布式鎖的功能， 像是 Redis 就是一個常被拿來做分布式鎖的工具，而 Laravel 本身有提供 Redis Lock 相關的 API，所以最後採用了這個解法。\n我們要達到的目的其實很簡單，也就是要把「撈出資料」和「新增資料」這兩個操作視為一個原子性的操作，如果第一個程序還沒執行完，第二個程序必須等待第一個做完後，才能接著做。利用分布式鎖的話就能夠實現這個行為： 當某一個程序還在執行這些動作的時候（還拿著這個鎖），其他程序都必須等待它執行完（釋放鎖）之後才能接著執行（獲得鎖）。如此一來就不會發生產生相同資料的問題。\n在使用 Laravel Redis Lock 之前，先看一下在 Redis 當中是怎麼實現 Lock 機制的。\nRedis Lock 機制 首先，在 redis-cli 下一個指令取得鎖\nSET resource_name my_random_value NX PX 30000 resource_name：鎖的 Key\nmy_random_value：鎖的 Value，實作上通常會設置一串 Random String，當作取得該鎖的 Client 識別符，在釋放鎖時需檢查 Key 所對應的 Value 是不是和取得鎖時所設置的 Value 相同，避免鎖被其他 Client 釋放\nNX：只有當 resource_name 不存在才創建這個 Key\nPX 30000： Key 的有效期間是 30000 毫秒，超過會自動失效\n就這樣！而「釋放鎖」的實作，通常會寫成一個 LUA 腳本，給 Redis 來執行：\n1 2 3 4 5 6 if redis.call(\u0026#34;GET\u0026#34;,KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;DEL\u0026#34;,KEYS[1]) else return 0 end 接著我們可以回到 Laravel 當中去使用 Redis Lock 了！\nLaravel Redis Lock 建立並取得鎖 首先要建立一個鎖，要先 new 一個 Illuminate\\Cache\\RedisLock\nIlluminate\\Cache\\RedisLock 實作 Illuminate\\Contracts\\Cache\\Lock interface，實現取得鎖、釋放鎖等功能，並繼承 Illuminate\\Cache\\Lock abstract class 共享分布式鎖的相同功能。\n1 2 3 4 use Illuminate\\Cache\\RedisLock; use Illuminate\\Support\\Facades\\Redis; $lock = new RedisLock(Redis::connection(), \u0026#34;creating:snapshot:$order-\u0026gt;id\u0026#34;, 15); 來看一下 Illuminate\\Cache\\RedisLock 的建構子寫了什麼\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // vendor/laravel/framework/src/Illuminate/Cache/RedisLock.php /** * Create a new lock instance. * * @param \\Illuminate\\Redis\\Connections\\Connection $redis * @param string $name * @param int $seconds * @param string|null $owner * @return void */ public function __construct($redis, $name, $seconds, $owner = null) { parent::__construct($name, $seconds, $owner); $this-\u0026gt;redis = $redis; } $name ：鎖的 Key。在我們的例子當中，Key 值應該會是 OrderSnapshot 的 order_id，因為我們就是為了避免相同 order_id 的 OrderSnapshot 被建立，所以要處理特定 order_id 時，應該要取得一個鎖，避免其他執行序也對相同 order_id 做處理。\n$seconds：Key 的有效期間\n$owner： 鎖的 Value。如果不帶該參數，Laravel 會幫我們產生一串亂數當成 Value。在 Illuminate\\Cache\\Lock 的建構子當中：\n1 2 3 4 5 6 7 8 9 10 11 // vendor/laravel/framework/src/Illuminate/Cache/Lock.php public function __construct($name, $seconds, $owner = null) { if (is_null($owner)) { $owner = Str::random(); } $this-\u0026gt;name = $name; $this-\u0026gt;owner = $owner; $this-\u0026gt;seconds = $seconds; } 然後呼叫 acquire 方法時，才會真的向 Redis 下指令建立鎖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // vendor/laravel/framework/src/Illuminate/Cache/RedisLock.php /** * Attempt to acquire the lock. * * @return bool */ public function acquire() { if ($this-\u0026gt;seconds \u0026gt; 0) { return $this-\u0026gt;redis-\u0026gt;set($this-\u0026gt;name, $this-\u0026gt;owner, \u0026#39;EX\u0026#39;, $this-\u0026gt;seconds, \u0026#39;NX\u0026#39;) == true; } else { return $this-\u0026gt;redis-\u0026gt;setnx($this-\u0026gt;name, $this-\u0026gt;owner) === 1; } } 釋放鎖 同樣定義在 RedisLock 的實作裡，使用了剛剛提到的 Lua 腳本，傳給 Redis 去執行，腳本內容就是同樣的內容，這邊就不貼了\n1 2 3 4 5 6 7 8 9 10 11 // vendor/laravel/framework/src/Illuminate/Cache/RedisLock.php /** * Release the lock. * * @return bool */ public function release() { return (bool) $this-\u0026gt;redis-\u0026gt;eval(LuaScripts::releaseLock(), 1, $this-\u0026gt;name, $this-\u0026gt;owner); } 取得鎖和釋放鎖的流程應該會類似這樣(偽代碼)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 while { if ($lock-\u0026gt;acquire()) { // 處理業務邏輯 $lock-\u0026gt;release(); break; } //maybe wait for seconds? sleep(); } 而 RedisLock 當中有一個 block 方法可以使用，已經幫我們處理了流程控制的部分，還能額外設置等待釋放鎖的超時時間（超過會拋出異常）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public function block($seconds, $callback = null) { $starting = $this-\u0026gt;currentTime(); while (! $this-\u0026gt;acquire()) { // - 7.x 之後的 laravel 會有 sleepMilliseconds 參數，預設為 250 毫秒 // - 7.x 以前的直接寫死 250 毫秒 usleep($this-\u0026gt;sleepMilliseconds * 1000); if ($this-\u0026gt;currentTime() - $seconds \u0026gt;= $starting) { throw new LockTimeoutException; } } // 取得鎖之後執行 callback 並釋放鎖 if (is_callable($callback)) { try { return $callback(); } finally { $this-\u0026gt;release(); } } return true; } 最後使用 block 方法，改寫我們一開始的程式碼：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $lock = new RedisLock(Redis::connection(), \u0026#34;creating:snapshot:$order-\u0026gt;id\u0026#34;, 15); return $lock-\u0026gt;block(5, function () use ($order) { $snapshot = OrderSnapshot::where(\u0026#39;order_id\u0026#39;, $order-\u0026gt;id)-\u0026gt;first(); if (!empty($snapshot)) { return $snapshot; } // do something... return OrderSnapshot::create([\u0026#39;payload\u0026#39; =\u0026gt; $order_array]); }); ","date":"Nov 06","permalink":"//localhost:1313/posts/%E5%9C%A8-laravel-%E7%95%B6%E4%B8%AD%E4%BD%BF%E7%94%A8-redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%8E%96-%E9%81%BF%E5%85%8D-race-condition-%E9%87%8D%E8%A4%87%E6%8F%92%E5%85%A5%E7%9B%B8%E5%90%8C%E8%B3%87%E6%96%99%E5%95%8F%E9%A1%8C/","tags":["Laravel","Redis"],"title":"在 Laravel 當中使用 Redis 分布式鎖 避免 race condition 重複插入相同資料問題"},{"categories":null,"contents":" recycle 方法的使用情境及欲解決之問題 在 laravel 9 factory 的文件當中最後一段是在說明 recycle 的使用情境與方法：\nIf you have models that share a common relationship with another model, you may use the recycle method to ensure a single instance of the related model is recycled for all of the relationships.\nFor example, imagine you have Airline, Flight, and Ticket models, where the ticket belongs to an airline and a flight, and the flight also belongs to an airline. When creating tickets, you will probably want the same airline for both the ticket and the flight, so you may pass an airline instance to the recycle method:\n大致上是說在遇到以下類型的關聯時\n一個 ticket 屬於一個 flight 與 一個 airline（ticket 身上有 flight_id 與 airline_id)，而 ticket 所屬於的 flight （flight 身上有 airline_id）也會屬於和 ticket 相同的 airline （ticket 的airline_id 和 flight 的 airline_id 相同）\n可以使用 recycle 方法來傳入會共用的 airline model 實體：\n1 2 3 Ticket::factory() -\u0026gt;recycle(Airline::factory()-\u0026gt;create()) -\u0026gt;create(); ok，然後這段解說就結束了。我看了好多遍還是滿頭疑惑。直到查到了這個原始的 PR，看了裡面的範例程式碼才理解了 recycle 的用意。\nPR 的作者展示了在沒有 recycle 方法時，如果要建一個滿足需求（ticket 屬於 flight 也屬於 airline，且 flight 的 airline 和 ticket 的 airline 相同）的 Ticket 會需要這樣寫：\n1 2 3 4 5 $airline = Airline::factory()-\u0026gt;create(); Ticket::factory() -\u0026gt;for($airline) -\u0026gt;for(Flight::factory()-\u0026gt;for($airline)) -\u0026gt;create(); 但有了 recycle 之後，可以改成這樣寫：\n1 2 3 4 $airline = Airline::factory()-\u0026gt;create(); Ticket::factory() -\u0026gt;recycle($airline) -\u0026gt;create(); 等於 recycle 幫我們把 ticket 所屬於的 airline ，以及 ticket 所屬的 flight 所屬的 airline 都指定成當成參數傳入 recycle 方法的那一個 airline 實例。 也就是說在建立 ticket 的過程中，當需要建立其關聯（關聯的關聯、關聯的關聯的關聯⋯⋯）model 時，只要遇到 \u0026ldquo;BelongsTo airline\u0026rdquo; 的關聯，都會直接使用該 airline 實例。\n測試一下是不是符合我們的想像，首先先開出這三個 Model 與 migration 後，再分別定義三者的 Factory：\nAirline 1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Airline extends Model { use HasFactory; public function tickets() { return $this-\u0026gt;hasMany(Ticket::class); } public function flights() { return $this-\u0026gt;hasMany(Flight::class); } } 1 2 3 4 5 6 7 8 9 10 // airline migration // default public function up() { Schema::create(\u0026#39;airlines\u0026#39;, function (Blueprint $table) { $table-\u0026gt;id(); $table-\u0026gt;timestamps(); }); } 1 2 3 4 5 6 7 8 9 // AirlineFactory ... public function definition() { return [ // ]; } Flights 1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Flight extends Model { use HasFactory; public function tickets() { return $this-\u0026gt;hasMany(Ticket::class); } public function airline() { return $this-\u0026gt;belongsTo(Airline::class); } } 1 2 3 4 5 6 7 8 9 10 // flight migration ... public function up() { Schema::create(\u0026#39;flights\u0026#39;, function (Blueprint $table) { $table-\u0026gt;id(); $table-\u0026gt;timestamps(); $table-\u0026gt;foreignId(\u0026#39;airline_id\u0026#39;)-\u0026gt;constrained(); }); } 1 2 3 4 5 6 7 8 // FlightFactory ... public function definition() { return [ \u0026#39;airline_id\u0026#39; =\u0026gt; Airline::factory() ]; } Tickets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Ticket extends Model { use HasFactory; public function flight() { return $this-\u0026gt;belongsTo(Flight::class); } public function airline() { return $this-\u0026gt;belongsTo(Airline::class); } } 1 2 3 4 5 6 7 8 9 10 11 // tickets migration ... public function up() { Schema::create(\u0026#39;tickets\u0026#39;, function (Blueprint $table) { $table-\u0026gt;id(); $table-\u0026gt;timestamps(); $table-\u0026gt;foreignId(\u0026#39;flight_id\u0026#39;)-\u0026gt;constrained(); $table-\u0026gt;foreignId(\u0026#39;airline_id\u0026#39;)-\u0026gt;constrained(); }); } 1 2 3 4 5 6 7 8 9 // TicketFactory ... public function definition() { return [ \u0026#39;flight_id\u0026#39; =\u0026gt; Flight::factory(), \u0026#39;airline_id\u0026#39; =\u0026gt; Airline::factory() ]; } tinker 執行結果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026gt;\u0026gt;\u0026gt; $ticket = App\\Models\\Ticket::factory()-\u0026gt;recycle(App\\Models\\Airline::factory()-\u0026gt;create())-\u0026gt;create(); =\u0026gt; App\\Models\\Ticket {#4619 flight_id: 1, airline_id: 1, updated_at: \u0026#34;2022-10-05 11:02:54\u0026#34;, created_at: \u0026#34;2022-10-05 11:02:54\u0026#34;, id: 1, } \u0026gt;\u0026gt;\u0026gt; $ticket-\u0026gt;airline =\u0026gt; App\\Models\\Airline {#3647 id: 1, created_at: \u0026#34;2022-10-05 11:02:54\u0026#34;, updated_at: \u0026#34;2022-10-05 11:02:54\u0026#34;, } \u0026gt;\u0026gt;\u0026gt; $ticket-\u0026gt;flight-\u0026gt;airline =\u0026gt; App\\Models\\Airline {#3628 id: 1, created_at: \u0026#34;2022-10-05 11:02:54\u0026#34;, updated_at: \u0026#34;2022-10-05 11:02:54\u0026#34;, } 確實 ticket 的 airline 和 ticket 的 flight 的 airline 都是 id 為 1 的 airline。\n原始碼分析 接著來看一下這個神奇的功能是如何被實現的。\n首先 recyle 方法會將要共用的實例暫存在 Factory 當中的 recyle 屬性當中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 //vendor/laravel/framework/src/Illuminate/Database/Eloquent/Factories/Factory.php L627 public function recycle($model) { // Group provided models by the type and merge them into existing recycle collection return $this-\u0026gt;newInstance([ \u0026#39;recycle\u0026#39; =\u0026gt; $this-\u0026gt;recycle -\u0026gt;flatten() -\u0026gt;merge( Collection::wrap($model instanceof Model ? func_get_args() : $model) -\u0026gt;flatten() )-\u0026gt;groupBy(fn ($model) =\u0026gt; get_class($model)), ]); } create 方法被呼叫後，進到 make ， 再進到 $this-\u0026gt;count === null if 敘述裡面\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //vendor/laravel/framework/src/Illuminate/Database/Eloquent/Factories/Factory.php public function make($attributes = [], ?Model $parent = null) { if (! empty($attributes)) { return $this-\u0026gt;state($attributes)-\u0026gt;make([], $parent); } if ($this-\u0026gt;count === null) { return tap($this-\u0026gt;makeInstance($parent), function ($instance) { // here $this-\u0026gt;callAfterMaking(collect([$instance])); }); } ... } 接著進到 makeInstance ，當中 newModel 時呼叫了 getExpandedAttributes 方法\n1 2 3 4 5 6 7 8 9 10 protected function makeInstance(?Model $parent) { return Model::unguarded(function () use ($parent) { return tap($this-\u0026gt;newModel($this-\u0026gt;getExpandedAttributes($parent)), function ($instance) { if (isset($this-\u0026gt;connection)) { $instance-\u0026gt;setConnection($this-\u0026gt;connection); } }); }); } 將 $this-\u0026gt;getRawAttributes($parent) 返回值（我們剛剛在每個 Model Factory 當中的 defination 方法回傳的陣列）當作參數塞進 expandAttributes 並回傳結果\n1 2 3 4 protected function getExpandedAttributes(?Model $parent) { return $this-\u0026gt;expandAttributes($this-\u0026gt;getRawAttributes($parent)); } 重點就在這裡，還記得前面所建立的 Model Factory 當中我們將 foreign key 分別指定為對應的 Factory\n1 2 3 4 5 6 7 8 9 // TicketFactory ... public function definition() { return [ \u0026#39;flight_id\u0026#39; =\u0026gt; Flight::factory(), \u0026#39;airline_id\u0026#39; =\u0026gt; Airline::factory() ]; } 在執行到\nApp\\Models\\Ticket::factory()-\u0026gt;recycle(App\\Models\\Airline::factory()-\u0026gt;create())-\u0026gt;create()\n的第二個 create （ TicketFactory::create）並且進到 expandAttributes 方法裡，當中的 $definition 其實就等同上面這個陣列內容（詳情可見 getRawAttributes 方法），所以 $attribute 分別會是 Flight::factory() 和 Airline::factory()\n而執行第一個迭代時（ $this = TicketFactory, $attribute = Flight::factory() ）由於在暫存的 recycle 屬性中找不到對應的 Flight Model，所以將 Flight::factory() 也傳入當前的 recycle 屬性後再 create。就是在這個地方形成遞迴，不斷把 recycle 傳給下一個屬於的關聯後再建立關聯 Model。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 protected function expandAttributes(array $definition) { return collect($definition) -\u0026gt;map($evaluateRelations = function ($attribute) { if ($attribute instanceof self) { ///*** $attribute = $this-\u0026gt;getRandomRecycledModel($attribute-\u0026gt;modelName()) ?? $attribute-\u0026gt;recycle($this-\u0026gt;recycle)-\u0026gt;create()-\u0026gt;getKey(); ///*** } elseif ($attribute instanceof Model) { $attribute = $attribute-\u0026gt;getKey(); } return $attribute; }) ... } 總結 之所以會有 recycle 這個方法，主要是為了可以使用同一個實例作為關聯且不需巢狀呼叫 for 方法。 重點在於 需事先在 Model Factory 當中將 {model}_id指定為對應的 Factory ({model}::factory()) ，要達到這點 recycle 才會有作用。\n個人是覺得文件沒有寫得非常清楚，花了一番力氣才真正理解它的用法，但也剛好可以理解一下原理啦。\n","date":"Oct 05","permalink":"//localhost:1313/posts/laravel-9-factory-recycle-method-%E7%94%A8%E6%B3%95%E8%88%87%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","tags":["Laravel"],"title":"Laravel 9 factory recycle method 用法與原理分析"},{"categories":null,"contents":" slice 資料結構 Golang 底層使用 SliceHeader 去描述運行時的 slice\n1 2 3 4 5 type SliceHeader struct { Data uintptr Len int Cap int } 對應一個 slice 具備的三個屬性：\nLen - slice 的長度 Cap - 底層陣列大小 Data - 底層 array 第一個元素的指標 slice 有點類似 java 的 ArrayList，len 就等同於 size，表示 list 當中的元素數量，而 cap 則對應 ArrayList 的 capacity，也就是底層陣列的大小。\n之所以特別強調 slice 所記錄的底層陣列指標是「陣列第一個元素的指標」，是因為要提醒不要忘了陣列的本質就是一串連續的記憶體空間，儲存第一個元素指標（位址）後即可藉由索引及元素大小來計算出其他索引確切的記憶體位址。\nSlice Assignment 1 2 3 s1 := make([]int, 0) s2 := s1 執行 s2 := s1 時，雖然是複製出另一個 slice（記憶體位置不同），但兩者的指標仍是同一個，都指向相同的陣列（起始位置）\n除非其中一個 slice 在 append 時，發現原本陣列空間不夠，因此建另一個新的陣列，才會造成兩者所指向的底層陣列不同，有關 append 的 reallocate 機制，參考：https://go.dev/blog/slices\n所以當新增一個如下的 slice：\n1 2 3 4 5 s1 := make([]int, 5, 10) fmt.Println(s1) // [0, 0, 0, 0, 0] fmt.Println(len(s1), cap(s1), \u0026amp;s1[0]) // 5 10 0xc0000ac002 等同新建一個大小為 10 的陣列，並在陣列填入 5 個 int 類型的 zero value，再把 slice 的 len 設為 5， cap 設為 10，並且紀錄陣列第一個元素的指標。\n用圖示表示：\n所以當我們要取超過 slice 長度(len)的元素\n1 fmt.Println(s1[5]) 會獲得一個 runtime error: index out of range [5] with length 5 的 panic\nSlice Assignment + append 方法的非預期行為 當要往一個 len 為 0 的 slice 當中添加元素時，會需要使用 append 方法，該方法會回傳一個更新後的 slice。通常都會這樣使用：\n1 2 nums := make([]int, 0, 8) nums = append(nums, 1) // append 過後的結果直接賦值給 nums 變數 延伸上面提到的 slice assignment 概念，當另外一個變數 newNums 也接收 append 後回傳的新 slice，兩個 slice (nums \u0026amp; newNums) 所指向底層陣列相同時，以下程式碼會印出什麼？\n1 2 3 4 5 6 7 8 9 10 11 12 13 nums := make([]int, 0, 8) nums = append(nums, 1) nums = append(nums, 2) nums = append(nums, 3) nums = append(nums, 4) nums = append(nums, 5) newNums := append(nums, 6) newNums = append(newNums, 7) nums = append(nums, 7) fmt.Println(newNums) fmt.Println(nums) 結果會是：\n1 2 [1 2 3 4 5 7 7] [1 2 3 4 5 7] 如果覺得意外的話，我們就一個個來看究竟發生什麼事吧。\n首先，在建立 newNums 之前， nums 跟底層陣列長這樣：\n接著到了 newNums := append(nums, 6) 這行，建立新的 slice 並且加了一個新的元素 6 到陣列：\n這時可能有人會問，既然底層陣列多了一個元素，然後原本的 nums 也指向這個陣列，那 nums 不就也會多一個元素嗎？\n但其實動到的是底層陣列而不是 num 這個 slice，因為 nums 本身的 len 並沒有改變（改變的是 newNums的 len ），剛剛前面有提到，當要取超過 slice 長度(len)的元素，會拋出例外。也就是說，在 nums 這個 slice 雖然本身底層陣列已經遭到改動了，但因爲我們都是透過 slice 去對底層陣列取值的 ，而 nums 的 len 還是 5，根本無法 reach 到 index 為 5 的元素。\n繼續往下到 newNums = append(newNums, 7) 這一行，底層陣列又多了一個 7：\n接著到 nums = append(nums, 7) 這行，由於 nums slice 最後一個元素的 index 等於 4，所以 append 方法是會將陣列 index 4+1=5 的位置放入 7 這個值，所以就造成 index 5 原本的值被取代：\n驗證 nums index 5 和 newNums index 5 的指標（記憶體位置）確實相同：\n1 2 3 4 5 6 7 8 9 10 11 12 newNums := append(nums, 6) fmt.Println(newNums[5], \u0026amp;newNums[5]) // 6 0xc000128068 -\u0026gt;這時候還是 6 newNums = append(newNums, 7) fmt.Println(newNums[6], \u0026amp;newNums[6]) // 7 0xc000128070 nums = append(nums, 7) fmt.Println(nums[5], \u0026amp;nums[5]) // 7 0xc000128068 -\u0026gt;被上面那行改成 7 fmt.Println(newNums[5], \u0026amp;newNums[5]) // 7 0xc000128068 -\u0026gt;和 nums 為同一個記憶體位置 fmt.Println(nums) // [1 2 3 4 5 7] fmt.Println(newNums) // [1 2 3 4 5 7 7] -\u0026gt; index 5 的值已被覆蓋 總結，slice 可以視作在陣列之上的一層“片段資訊”，藉由這個片段，我們可以對底層陣列取值、增刪改元素，同時也允許多個片段向同個陣列操作，不同片段取的索引範圍可能也不同。但也是因此必須非常小心，因為只要底層陣列一被改動，所有參考該陣列的 slice 都可能會受到影響。\n","date":"Aug 16","permalink":"//localhost:1313/posts/golang-slice-assignment-%E8%88%87-append-%E6%96%B9%E6%B3%95/","tags":["Golang"],"title":"Golang Slice Assignment 與 append 方法"},{"categories":null,"contents":"測試時若涉及第三方服務，往往會需要運用到 Mock （測試替身）的概念，將外部模組代換成一個假的物件，並模擬其行為與回傳值，讓我們能專注於業務邏輯的單元測試。\n當前的情境為，在 Repository 裡使用 aws SDK for go 當中的 dynamodb client 來建立與 dynamodb 的連線以及後續相關對資料庫的操作。但在進行測試時，為了避免每次跑測試都要真的戳資料庫（因在單元測試中，我們只想要確定與 dynamodb client 的互動有確實呼叫預期的方法、傳入相應的參數，而不在乎資料庫到底有沒有寫入資料這種事），會需要將這個 client 替換成 Mock 物件。\n而 aws SDK for go 就提供了一個方便開發者進行 mocking 的 interface：dynamodb interface\n我們可以直接使用 dynamodb interface 作為依賴的類型，也就是說如果要放一個 dynamodb client 在 struct 裡面，原本可能會直接使用 *dynamodb.DynamoDB 類型：\n1 2 3 4 5 6 7 8 type dynamodbUserNotificationRepository struct { Client *dynamodb.DynamoDB } // 實例化時注入 dynamodb client 依賴 func NewDynamondbUserNotificationRepository(Client *dynamodb.DynamoDB) domain.UserNotificationRepository { return \u0026amp;dynamodbUserNotificationRepository{Client} } 但為了之後方便在測試時能輕鬆注入 Mock 物件，可以替換成 dynamodbiface.DynamoDBAPI ：\n1 2 3 4 5 6 7 type dynamodbUserNotificationRepository struct { Client dynamodbiface.DynamoDBAPI // instead of *dynamodb.DynamoDB } func NewDynamondbUserNotificationRepository(Client dynamodbiface.DynamoDBAPI) domain.UserNotificationRepository { return \u0026amp;dynamodbUserNotificationRepository{Client} } 繼續完整這個範例，假設 dynamodbUserNotificationRepository 有一個 Store 方法：\n1 2 3 func (d *dynamodbUserNotificationRepository) Store(ctx context.Context, user_notification_input *domain.UserNotificationRequestInputStore, batch string) (user_notification *domain.UserNotification, err error) { // 裡面會呼叫到 d.Client.PutItem 方法 } 要測試上面這個 Store 方法，需要將 dynamodbUserNotificationRepository 裡面的 Client 取代成 Mock 物件，所以我們先按照官方文件範例定義一個 Mock client struct：\n1 2 3 type MockDynamoDBClient struct { dynamodbiface.DynamoDBAPI } 接著複寫 PutItem 方法，回傳 dummy 資料：\n1 2 3 func (m *mockDynamoDBClient) PutItem(input *dynamodb.PutItemInput) (*dynamodb.PutItemOutput,error) { return \u0026amp;dynamodb.PutItemOutput{}, nil } 然後就可以在測試中 new 一個 mockDynamoDBClient 傳入 NewDynamondbUserNotificationRepository：\n1 2 3 4 5 func TestStore(t *testing.T) { mockSvc := \u0026amp;mockDynamoDBClient{} repo := repository.NewDynamondbUserNotificationRepository(mockSvc) // do something... } 感覺就很開心地寫完測試了。但如果同時有另外一個方法也會呼叫 PutItem ，而在為這個方法寫測試時，PutItem 的回傳值必須不同，該怎麼辦？首先想到的可能是再另外寫個 Mock client 2，但有 n 個難道要寫 n 次嗎？\n這就是 testify/mock 出場的時候了，使用它能讓我們在個別測試裡定義 Mock 物件會被呼叫的方法名及其回傳值。\n將 MockDynamoDBClient 修改為：\n1 2 3 4 type MockDynamoDBClient struct { dynamodbiface.DynamoDBAPI // 1. mock.Mock // (多加上的部分) 2. } 這裡同時使用到兩個 package 提供的 interface 以及 struct\naws/aws-sdk-go dynamodbiface.DynamoDBAPI: 依照官方文件範例，將 dynamodbiface.DynamoDBAPI interface 用匿名的方式嵌進 Mock client struct 裡面，使得該 struct 等同”繼承”了這些 interface 當中的方法，因此可以被視為一個有實現該 interface 的 struct。 stretchr/testify mock.Mock: 依照官方範例，在定義 Mock client struct 當中嵌入 mock.Mock（同樣會有”繼承“ mock.Mock 裏的方法的效果）。 兩者都利用到了 golang struct embed 的特性，關於 golang 的 struct with embedded anonymous interface 有空會再寫另一篇筆記來解釋。 Ref：https://stackoverflow.com/a/24546029/10943670\n接著定義 mock client 待會在測試中會被呼叫到的方法：\n1 2 3 4 func (m *MockDynamoDBClient) PutItem(input *dynamodb.PutItemInput) (*dynamodb.PutItemOutput,error) { arg := m.Called(input) // 1. return arg.Get(0).(*dynamodb.PutItemOutput), arg.Error(1) // 2. } 取得參數: 這裏的 Called 方法會取得 PutItem 方法被呼叫之後應該要回傳的參數，待會會在寫測試時實際定義，總之這邊就是預期會得到一組在測試時定義的回傳參數。 類型檢查: 檢查得到的參數是否符合類型，是的話才會真的將其當成 PutItem 方法的回傳值傳出去。 arg.Get(0).(*dynamodb.PutItemOutput) 表示得到的第一個參數必須是 *dynamodb.PutItemOutput 類型，arg.Error(1) 表示得到的第二個參數必須是 Error 類型，若不符合類型會引發 panic。 官方文件：https://github.com/stretchr/testify/blob/master/mock/doc.go\n最後來跑一次加入了 mock.Mock 之後的整個測試流程吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func TestStore(t *testing.T) { mockSvc := \u0026amp;mockDynamoDBClient{} // 1. mockSvc.On(\u0026#34;PutItem\u0026#34;, mock.Anything).Return(\u0026amp;dynamodb.PutItemOutput{}, nil).Once() // 2. repo := repository.NewDynamondbUserNotificationRepository(mockSvc) // 3. // other arrangements... // action ret, err := repo.Store(context.TODO(), mockedInput, batch) // 4. // assertions... } 首先實例化一個 Mock client 重點在於這個部分，使用了 mock.Mock 當中的方法，分別解釋各個方法作用： On(\u0026quot;PutItem\u0026quot;, mock.Anything) ：斷言呼叫該物件的 PutItem 方法時會收到一個任意參數 mock.Anything Return(\u0026amp;dynamodb.PutItemOutput{}, nil) ：也就是上面提到的 Called 方法被呼叫後的回傳值 Once() ：斷言該方法應該要被呼叫一次 再來將 Mock client 物件注入 NewDynamondbUserNotificationRepository 呼叫 repo.Store(context.TODO(), mockedInput, batch) 時，裡面將會呼叫 Mock client 的 PutItem 方法 以上就是結合 aws SDK for go 所提供的 dynamodb interface 搭配 testify/mock 進行單元測試的方法～\n","date":"Aug 04","permalink":"//localhost:1313/posts/mock-dynamodb-clientuse-aws-sdk-for-golang-with-testify-mock/","tags":["Golang","Testing"],"title":"Mock Dynamodb Client(use aws SDK for golang) with testify/mock"},{"categories":null,"contents":" 由於以下所分析的原始碼是舊版(5.5)的 laravel，但因為本文主要探討 IoC 在特定 method 的依賴解析，核心概念是不變的，但可能不同版本在部分程式碼上面會有些許差異。\n熟悉 Laravel 的人應該都曉得 IoC Container 的強大之處，在 laravel 當中，可以簡單地透過一行 app(MyClass::class) 取得已經被注入依賴後 Class 的實例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Dependence1 { function foo() { echo \u0026#34;foo\u0026#34;; } } class Dependence2 { function foo2() { echo \u0026#34;foo2\u0026#34;; } } final class MyClass { private $dep1; private $dep2; public function __construct( Dependence1 $dependence1, Dependence2 $dependence2 ) { $this-\u0026gt;dep1 = $dependence1; $this-\u0026gt;dep2 = $dependence2; } } app(MyClass::class); // maybe $this-\u0026gt;app-\u0026gt;make(MyClass::class) in ServiceProvider 這是一個 laravel 實現控制反轉(IoC)的簡單例子 ，MyClass 的建構子當中的兩個引數(依賴的Class) 被 container 讀取到後，先分別被實例化並作為參數傳進 MyClass 的建構子，最後返回實例化完成的 MyClass 物件。(每次拜讀到這邊真的是想跪 laravel 作者）\nIoC 的核心理念就是將原本在下層（具體）的程式碼中「注入依賴」這個行為，提升至上層（抽象）去控制決定要給該 Class 注入什麼依賴，也就是說下層的 Class 需要依賴時，都會向上層去要他所需要的依賴實例（特定 Class 或是 implement 特定 Interface 的實例）。\nlaravel 當中許多基礎核心的 Class 在底層也是這麼運作的，例如 Controller 也是經由 IoC Container 實例化，所以我們才能夠在 Controller 建構子的引數寫一堆依賴然後開心地使用。\n1 2 3 4 5 6 7 8 9 10 11 12 class MyController extends Controller { protected $logger; public function __construct(Logger $logger) { $this-\u0026gt;logger = $logger; } public function index() { $this-\u0026gt;logger-\u0026gt;error(\u0026#39;Something happened\u0026#39;); } } 然而，laravel 不只會自動解析在建構子引數當中的 Dependencies，在某些特定 Class 當中，laravel 也會自動解析 method 引數中的依賴，最常見的的就是我們的 Controller：\n1 2 3 4 5 6 7 8 class MyController extends Controller { public function show(Logger $logger, $id) { $logger-\u0026gt;error(\u0026#39;Something happened\u0026#39;); } } 到底其背後是怎麼實現這個功能的呢？以下就開始 trace code 來看看吧。\n首先，一個 Request 的旅程就是從 Illuminate\\Contracts\\Http\\Kernel 開始， 在 index.php 當中，實例化 Kernel Class 之後， 呼叫了 handle 這個 method：\n1 2 3 4 5 6 7 // public/index.php $kernel = $app-\u0026gt;make(Illuminate\\Contracts\\Http\\Kernel::class); $response = $kernel-\u0026gt;handle( $request = Illuminate\\Http\\Request::capture() ); 可以在 bootstrap/app.php 當中找到該抽象對應的綁定，也就是 App\\Http\\Kernel ：\n1 2 3 4 5 6 // bootstrap/app.php $app-\u0026gt;singleton( Illuminate\\Contracts\\Http\\Kernel::class, App\\Http\\Kernel::class ); 接著， App\\Http\\Kernel 又 extend 了 Illuminate\\Foundation\\Http\\Kernel ，handle 方法就在這個 Class 當中定義，重點是 sendRequestThroughRouter 這個 method，準備要將 Request 分配給 Router (上面都還在 application 層，從這邊開始進到 framework 裡面)：\n1 2 3 4 5 6 7 8 9 10 // vendor/laravel/framework/src/Illuminate/Foundation/Http/Kernel.php public function handle($request) { try { $request-\u0026gt;enableHttpMethodParameterOverride(); $response = $this-\u0026gt;sendRequestThroughRouter($request); ... } 1 2 3 4 5 6 7 8 9 10 11 // vendor/laravel/framework/src/Illuminate/Foundation/Http/Kernel.php protected function sendRequestThroughRouter($request) { ... return (new Pipeline($this-\u0026gt;app)) -\u0026gt;send($request) -\u0026gt;through($this-\u0026gt;app-\u0026gt;shouldSkipMiddleware() ? [] : $this-\u0026gt;middleware) -\u0026gt;then($this-\u0026gt;dispatchToRouter()); // 將 Request 分配給 Router } 1 2 3 4 5 6 7 8 9 10 // vendor/laravel/framework/src/Illuminate/Foundation/Http/Kernel.php protected function dispatchToRouter() { return function ($request) { $this-\u0026gt;app-\u0026gt;instance(\u0026#39;request\u0026#39;, $request); return $this-\u0026gt;router-\u0026gt;dispatch($request); }; } 接下來要進入到 Router 的階段，有些不是很相關的部分就直接跳過不貼程式碼了，進到 Router 後的 method 呼叫順序是 dispatch → dispatchToRoute → runRoute -\u0026gt; runRouteWithinStack\n來看一下 在 runRouteWithinStack 當中倒數第三行 $route-\u0026gt;run() ，這裡即將要準備解析在 routes/xxx.php 當中所定義的 Route 所指定的對應 Controller 以及 Controller method：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // vendor/laravel/framework/src/Illuminate/Routing/Router.php protected function runRouteWithinStack(Route $route, Request $request) { ... return (new Pipeline($this-\u0026gt;container)) -\u0026gt;send($request) -\u0026gt;through($middleware) -\u0026gt;then(function ($request) use ($route) { return $this-\u0026gt;prepareResponse( $request, $route-\u0026gt;run() ); }); } 這邊進入了 Route，主要在準備執行 Route 指定對應的 Controller 以及 Controller method，進到 $this-\u0026gt;runController() 的部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // vendor/laravel/framework/src/Illuminate/Routing/Route.php public function run() { $this-\u0026gt;container = $this-\u0026gt;container ?: new Container; try { if ($this-\u0026gt;isControllerAction()) { return $this-\u0026gt;runController(); // !!! } return $this-\u0026gt;runCallable(); } catch (HttpResponseException $e) { return $e-\u0026gt;getResponse(); } } 這裡會呼叫到 ControllerDispatcher 的 dispatch 方法接手處理：\n1 2 3 4 5 6 7 8 // vendor/laravel/framework/src/Illuminate/Routing/Route.php protected function runController() { return $this-\u0026gt;controllerDispatcher()-\u0026gt;dispatch( $this, $this-\u0026gt;getController(), $this-\u0026gt;getControllerMethod() ); } 挖了這麼深，終於要到重頭戲了，也就是呼叫了 $this-\u0026gt;resolveClassMethodDependencies 這個 method，並將路由上面所帶的參數、已實例化後的 Controller 以及 method 名稱做為參數傳入：\n1 2 3 4 5 6 7 8 9 10 11 // vendor/laravel/framework/src/Illuminate/Routing/ControllerDispatcher.php public function dispatch(Route $route, $controller, $method) { $parameters = $this-\u0026gt;resolveClassMethodDependencies( $route-\u0026gt;parametersWithoutNulls(), $controller, $method ); ... return $controller-\u0026gt;{$method}(...array_values($parameters)); } resolveClassMethodDependencies 呼叫了 resolveMethodDependencies，並將剛剛的路由參數以及一個新的 ReflectionMethod 實例做為參數傳入，原來實現 Method Dependency injection 的重要功臣就是 ReflectionMethod 這個東西，藉由 ReflectionMethod，我們可以獲得某個 instance 裡面關於某個 method 的資訊，包括可以知道他有哪些引數，而這也就是如何得以偵測到這些 method 需要的依賴，並且預先解析好物件當真正要呼叫這個 method 時再將已解析好的物件帶入的關鍵。\n1 2 3 4 5 6 7 8 9 10 11 12 // vendor/laravel/framework/src/Illuminate/Routing/RouteDependencyResolverTrait.php protected function resolveClassMethodDependencies(array $parameters, $instance, $method) { if (! method_exists($instance, $method)) { return $parameters; } return $this-\u0026gt;resolveMethodDependencies( $parameters, new ReflectionMethod($instance, $method) ); } 我們來看看 resolveMethodDependencies 裡面做了什麼：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // vendor/laravel/framework/src/Illuminate/Routing/RouteDependencyResolverTrait.php public function resolveMethodDependencies(array $parameters, ReflectionFunctionAbstract $reflector) { $instanceCount = 0; $values = array_values($parameters); foreach ($reflector-\u0026gt;getParameters() as $key =\u0026gt; $parameter) { $instance = $this-\u0026gt;transformDependency( $parameter, $parameters ); if (! is_null($instance)) { $instanceCount++; $this-\u0026gt;spliceIntoParameters($parameters, $key, $instance); } elseif (! isset($values[$key - $instanceCount]) \u0026amp;\u0026amp; $parameter-\u0026gt;isDefaultValueAvailable()) { $this-\u0026gt;spliceIntoParameters($parameters, $key, $parameter-\u0026gt;getDefaultValue()); } } return $parameters; } 這邊另外注意，傳入的 parameters 當中可能包含 primitive 值，因為在 Route 當中可能會這樣定義：\n1 2 3 4 5 6 7 8 9 10 // in routes Route::get(\u0026#39;countries.{country}\u0026#39;, \u0026#39;CountryController@show\u0026#39;)-\u0026gt;name(\u0026#39;countries.show\u0026#39;); // in Controllers public function show($country, Request $request) { ... } 若 endpoint 為 /api/countries/1 ，我們將 $parameters 、 $reflector-\u0026gt;getParameters() dd 出來看：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // $parameters array:1 [ \u0026#34;country\u0026#34; =\u0026gt; \u0026#34;1\u0026#34; ] // $reflector-\u0026gt;getParameters() array:2 [ 0 =\u0026gt; ReflectionParameter {#1228 +name: \u0026#34;country\u0026#34; position: 0 } 1 =\u0026gt; ReflectionParameter {#1229 +name: \u0026#34;request\u0026#34; position: 1 typeHint: \u0026#34;Illuminate\\Http\\Request\u0026#34; } ] 所以在遍歷每個從 ReflectionMethod 得到的 method 引數時 ($reflector-\u0026gt;getParameters())，首先會嘗試根據 TypeHint 將其實例化（如果該引數有 typeHint ），若能成功解析出實例，再按照正確位置塞入 $parameters 當中，最後回傳該 $parameters 陣列給vendor/laravel/framework/src/Illuminate/Routing/ControllerDispatcher@dispatch\n將這些解析完畢的依賴參數傳入相對應的 Controller method 執行：\n1 $controller-\u0026gt;{$method}(...array_values($parameters)); 至此已經大致將 laravel 實現 Controller method 自動注入依賴的核心部分都看完了，理解了核心概念再來看這些實作的程式碼後，感覺一切不再那麼 magic 了～\n參考資料 Laravel: Up \u0026amp; Running (Book) CHAPTER 11. The The Container https://www.php.net/manual/en/class.reflectionmethod.php ","date":"Jul 18","permalink":"//localhost:1313/posts/laravel-ioc-container-%E5%A6%82%E4%BD%95%E8%A7%A3%E6%9E%90-controller-method-%E7%95%B6%E4%B8%AD%E7%9A%84%E4%BE%9D%E8%B3%B4/","tags":["Laravel"],"title":"Laravel IoC Container 如何解析 Controller method 當中的依賴(DI)"},{"categories":null,"contents":"本來一直都用迴圈去處理同時發多個 request（很好懂但有點難處理 Error），這次親自來試試 Promise.all() 總算體驗到平行處理非同步的威力（？）於是紀錄一下心得以及和 await + axios 連用時的一些眉角。\nPromise.all() 用法 Promise.all (iterable) 接受一個 iterable 物件（通常是陣列）作為參數，當裡面每個元素都是 Promise 物件時(也可以不是，待會會提到），它就會平行去處理這些 Promise。由於其本身會回傳一個 Promise 物件，所以我們同樣可以用 then 或 await 去接他的 resolve/reject。 當所有的 Promise 都被 resolve 後才會回傳 resolve，其值會是全部的 Promise 處理完後所回傳的 resolve 值所組成的陣列。但若其中有一個 Promise 被 reject 就會直接拋出該 Promise 所回傳的錯誤。\n1 2 3 4 5 6 7 8 9 10 11 const array1 = [1, 4, 9, 16]; const promiseArr = array1.map(x =\u0026gt; Promise.resolve(x)); console.log(promiseArr) // [Promise, Promise, Promise, Promise] // 用 then 接結果 Promise.all(promiseArr).then(vals =\u0026gt; { console.log(vals) // [1, 4, 9, 16] }) // 用 await 接結果 const vals = await Promise.all(promiseArr) console.log(vals) // [1, 4, 9, 16] 提醒： await 後面接的一定會是一個 Promise （或 async function），他會幫我們把 Promise 處理完後直接吐給我們 resovle 或 reject 的值。\n而當陣列裡面有非 Promise 物件的元素存在時，Promise.all() 仍會輸出該元素的值：\n1 2 3 4 let a = 1 let b = Promise.resolve(2) let result = await Promise.all([a, b]) console.log(result) // [1, 2] Promise.all() + axios 我們可以先透過 map() 處理原始陣列（map()會回傳新的陣列），把原始陣列改成一組 Promise 陣列。以下面程式碼為例， products 為一組商品物件的陣列，在此即利用 map () 遍歷每個商品物件，在 map() 的 callback function 裡直接呼叫 axios 將商品資訊帶入 request body 發送請求，由於 axios 本身就會回傳 Promise，所以我們就能成功拿到一組 Promise 陣列並直接塞進 Promise.all 裡面囉！\n1 2 3 4 5 6 7 8 let data = await Promise.all(this.products.map((product) =\u0026gt; { return this.$axios.post(\u0026#39;http://localhost:8000/api/products\u0026#39;, { name: product.name, price: product.price, order_id: myOrder_id }) })) console.log(data) 所以我們會得到一個陣列長這樣：\n這時發現它長得好像不是我們要的 response data，那是因為 axios 的 response （resolve value）並非直接回 server 給我們的資料 ，而裡面那層 data 才是我們要的資料：\n1 2 3 4 5 6 7 8 { data: {}, //這才是 server 回給我們的資料 status: 200, statusText: \u0026#39;OK\u0026#39;, headers: {}, config: {}, request: {} } ","date":"Jun 30","permalink":"//localhost:1313/posts/promise-all%E8%88%87async-await%E5%92%8Caxios/","tags":["Javascript"],"title":"Promise.all() 與 async/await"},{"categories":null,"contents":"平常在實作 Vue 組件之間的資料傳遞大部分都是透過 props 及 $emit，或是直接經由 Vuex 進行狀態管理，而除了這兩種方法，還有另外一種做法是透過 $attrs 及 $listenter。\n本身也是因為之前偶然在查資料的時候看到這兩個 API，但當時看過別人寫的文章後卻只是似懂非懂，頂多知道有這個東西但不知道如何使用或該用在什麼場合，一直到實作時才真正理解它的用法，但多看多讀總是好的，有一天或許派得上用場。\n$attrs 其實簡單說就是子組件可以透過$attrs取得父組件當中除了 Props 以外的所有資料。\n乍看之下好像沒什麼，那不就直接用 Props 就好了嗎？ 但當在多重組件嵌套的情況之下，就會顯得很有用。我們先定義出三個組件，他們分別是： a-component（爺組件/模板）、b-component（父組件）、c-component（孫組件）\n我們可以在 a 使用 b：\n1 2 3 4 5 6 // a-component \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;b-component :msg=\u0026#34;hello\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; 接著在 b 中我們可以使用 $attrs 而不用透過 Props 拿到 apiUrl，並且將 $attrs 透過 v-bind 綁定在 c 上傳給 c 使用：\n1 2 3 4 5 6 7 // b-component \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;{{ $attrs.data }}\u0026lt;/h1\u0026gt; \u0026lt;c-component v-bind=\u0026#34;$attrs\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; 然後同樣在 c 當中我們就能夠透過$attrs取得 a 的資料 。這樣一來的好處就是當我們有多個資料要從 a 傳給 b 跟 c 共用時，不用每一層都要聲明 Props，然後還要將每個 Props 寫在 component 的標籤裡面：\n1 2 3 4 5 6 // c-component \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;{{ $attrs.data }}\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; 和 $attrs 相關的 API 還有 inheritAttrs，其值為布林值，預設為 true，也就是如果我們沒有特別將其設定成 false，子組件默認可以透過 $attrs 取得在父組件當中非透過 Props 繼承的資料。\n$listeners 應該不難猜想， $attrs 對應 Props ，$listeners 則對應 $emit。 簡單來說就是父組件可以透過 $listeners 取得所有子組件 $emit 打出來的事件。同樣以上面三個組件為例：\n1 2 3 4 5 6 // c-component \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;button @click=\u0026#34;$emit(\u0026#39;sayHi\u0026#39;)\u0026#34;\u0026gt; click me!\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; 在 b 當中同樣可以透過 v-on=\u0026quot;$listeners\u0026quot;將 c 事件委任給 a：\n1 2 3 4 5 6 // b-component \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;c-component v-on=\u0026#34;$listeners\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; a 就可以直接處理 c 打出的$emit事件，而不用透過 b 再 emit 一次\n1 2 3 4 5 6 // a-component \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;b-component @sayHi=\u0026#34;anEventHandler\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; 總結 所以當多重組件之間需要溝通傳遞，但不想用 Vuex 時，可以嘗試採用這兩種方法： * $attrs：孫組件取得爺組件的資料 * $listeners：爺組件直接觸發孫組件的事件\n","date":"Jun 23","permalink":"//localhost:1313/posts/vue%E7%88%BA%E5%AD%AB%E7%B5%84%E4%BB%B6%E8%B3%87%E6%96%99%E5%82%B3%E9%81%9E/","tags":["Vue"],"title":"Vue $attrs/$listeners 爺孫組件資料傳遞"},{"categories":null,"contents":"第一次使用 Echarts 這套圖形 library，在 vue 中使用 Echarts 可以直接裝 vue-echart，官方文件推薦兩個都裝：\n$ npm install echarts vue-echarts 預料之中的踩了不少坑，在此紀錄一些重點。\n安裝完後引入並註冊圖表 component 1 2 3 4 5 6 7 8 9 import Vue from \u0026#39;vue\u0026#39; import ECharts from \u0026#39;vue-echarts\u0026#39; import \u0026#39;echarts/lib/chart/bar\u0026#39; import \u0026#39;echarts/lib/component/tooltip\u0026#39; import \u0026#39;echarts-gl\u0026#39; //等等會使用 grapic 設定圖形文字，故需載入此 module Vue.component(\u0026#39;v-chart\u0026#39;, ECharts) // 註冊為 global component 基礎使用 在 template 中可以直接使用圖表 component，其接收 options 為 props，裡面的series屬性為設置特定類型圖表的屬性，在此使用專案中的圓餅圖當範例：\n1 \u0026lt;v-chart :options=\u0026#34;options\u0026#34; /\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 data() { return { options: { series: [ { type: \u0026#39;pie\u0026#39;, // 必須 name: \u0026#39;test\u0026#39;, // 必須 radius: [\u0026#39;50%\u0026#39;, \u0026#39;70%\u0026#39;], label: { normal: { show: false }, emphasis: { show: true, formatter: \u0026#39;{b} {@percentage}%\u0026#39; } }, data: [ { name: \u0026#39;韓國\u0026#39;, value: 70 }, { name: \u0026#39;日本\u0026#39;, value: 10 }, { name: \u0026#39;台灣\u0026#39;, value: 10 }, { name: \u0026#39;越南\u0026#39;, value: 6 }, { name: \u0026#39;中國\u0026#39;, value: 3 }, { name: \u0026#39;其他\u0026#39;, value: 1 } ] } ] } } } 圓餅圖中間加入文字 注意：一定要裝 echarts-gl 模組，否則會無法顯示。 可以直接利用官方提供的屬性grapic為圖表自行添加圖形元素，並新增特定文字（可以新增的圖形元素類型還有圖片、圖形等，可以參考文件），格式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 graphic: [ { type: \u0026#39;text\u0026#39;, left: \u0026#39;center\u0026#39;, top: \u0026#39;center\u0026#39;, style: { text: \u0026#39;學生國籍比例\u0026#39;, textAlign: \u0026#39;center\u0026#39;, fill: \u0026#39;#666\u0026#39;, font: \u0026#39;20px \u0026#34;STHeiti\u0026#34;, sans-serif\u0026#39; } } ] 圖例說明（legend）需要添加 value 資料 echarts 提供的 formater callback function 只有給我們 name 這個參數，所以要同時拿到 value 的話，會需要自己從圖表實例裡面找。\n注意：必須使用箭頭函式才能拿到這個 component 的實例，進而取得 options.series[0].data 得到我們要的 value\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 legend: { orient: \u0026#39;verticle\u0026#39;, left: \u0026#39;left\u0026#39;, bottom: \u0026#39;middle\u0026#39;, textStyle: { fontSize: 16 }, formatter: name =\u0026gt; { const data = this.options.series[0].data let targetValue data.map(item =\u0026gt; { if (item.name === name) { targetValue = item.value } }) return name + \u0026#39; \u0026#39; + targetValue + \u0026#39;%\u0026#39; } }, 圖表的響應 由於一開始設定圖例的排列方式為垂直排列、靠左並置中，但在行動裝置上這樣會破版，所以首先第一步先設定讓整個 Canvas 可以自適應容器大小縮放，實現方法其實只要修改 CSS 即可：\n1 2 3 4 .echarts { width: 100%; height: 400px; } 接著就會面臨到圖例跟圖表本體重疊的問題，所以我們需要偵測視窗寬度大小，隨著裝置寬度不同改變圖例排列的方式。\n1. 首先先在 component 上綁定 ref 1 \u0026lt;v-chart ref=\u0026#34;myChart\u0026#34; :options=\u0026#34;options\u0026#34; /\u0026gt; 2. 在 mounted 當中監聽 window 的 load event，當頁面載入時計算當前螢幕寬度大小，再透過 ref 屬性訪問該圖表實例並修改其 options.legend 屬性（和圖例定位相關的屬性） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 window.addEventListener(\u0026#39;load\u0026#39;, () =\u0026gt; { this.windowWidth = window.screen.width let orient, left, bottom if (this.windowWidth \u0026lt; 480) { orient = \u0026#39;horizontal\u0026#39; left = \u0026#39;center\u0026#39; bottom = \u0026#39;bottom\u0026#39; } else { orient = \u0026#39;vertical\u0026#39; left = \u0026#39;left\u0026#39; bottom = \u0026#39;middle\u0026#39; } if (this.$refs.myChart) { this.$refs.myChart.options.legend.orient = orient this.$refs.myChart.options.legend.left = left this.$refs.myChart.options.legend.bottom = bottom } }) 注意：此綁定方法只有在頁面第一次渲染時才會有效，如果要實現 RWD 要再另外監聽 resize 事件。\n結語 1. 如果要用到較多客製化功能要用 Echarts，否則才用 v-charts 在加入圓餅中間文字那裡卡滿久，原因是一開始裝的是 v-charts（算是輕量簡化版的 Echarts），推測目前還沒有支援到可以使用圖形文字（各種方式加入 graphic 屬性都未起作用），雖然也可能只是尚未找到解決方案（翻文件快翻到發瘋）。\n2. 在 Vue 當中取得圖表實例的方法 在 options 內部若用到其提供的回調函式，必須使用箭頭函式，拿到的 this才會是我們要的圖表實例物件（否則會是 undefined）。但在其他地方（Vue 的環境中）則要透過訪問 DOM 元素才能得到圖表實例物件。 目前的方法是這樣，但其實官方好像有提供其他可以訪問 options的 API（如 computedOptions，可參考文件） ，但我目前是都沒有成功過 QwQ，可能還需另外研究。\n","date":"Jun 11","permalink":"//localhost:1313/posts/%E4%BD%BF%E7%94%A8vue-echarts%E8%B8%A9%E7%9A%84%E5%9D%91/","tags":["Vue"],"title":"使用 vue-echarts 踩的坑"},{"categories":null,"contents":"以前本來會發表文章在 Medium，但某天實在是受不了 Medium 的醜程式碼區塊了。想起很久以前有用 Github Pages 架過一個 Hexo 部落格，但荒廢許久，也想玩點新東西，就又用 Hugo 弄了一個。把 Hexo 僅存的兩三篇文章搬過來，但 Medium 的就懶得搬了。於是有了這個部落格。\nP.S.但其實 Medium 在 2022 年底時的改版有支援比較美觀的程式碼區塊，不過我也懶得再換回去了。\n身為一個有點強迫症的人寫文章真的不是一件簡單的事，總要保證每個字句都通順，看不慣會一直想改。不過因為實在 Z\u0026gt;B，還是期許自己能夠繼續下去，一邊學習一邊紀錄。如果能因此幫助到一些也遇過相同問題的人，那就更開心了！內文中有任何錯誤或疑慮的地方，也請不吝指正，我會非常～感謝的！\n主要就是發表一些網頁/程式/軟體開發相關的技術筆記。歡迎留言或來信交流或申請加入兔兔教（並沒有這種東西）⸜( ˙ ˘ ˙)⸝\n","date":"Jan 01","permalink":"//localhost:1313/about/","tags":null,"title":"About"},{"categories":null,"contents":"","date":"Jan 01","permalink":"//localhost:1313/articles/","tags":null,"title":"Articles"}]